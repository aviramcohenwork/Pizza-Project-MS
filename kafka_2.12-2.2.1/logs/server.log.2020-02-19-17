[2020-02-17 16:37:47,364] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-02-17 16:37:47,365] ERROR Invalid config, exiting abnormally (org.apache.zookeeper.server.quorum.QuorumPeerMain)
org.apache.zookeeper.server.quorum.QuorumPeerConfig$ConfigException: Error processing .\config\zookeeper.properties
	at org.apache.zookeeper.server.quorum.QuorumPeerConfig.parse(QuorumPeerConfig.java:156)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:104)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:81)
Caused by: java.lang.IllegalArgumentException: .\config\zookeeper.properties file is missing
	at org.apache.zookeeper.server.quorum.QuorumPeerConfig.parse(QuorumPeerConfig.java:140)
	... 2 more
[2020-02-17 16:41:58,842] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-02-17 16:41:58,846] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-17 16:41:58,846] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-17 16:41:58,846] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-17 16:41:58,846] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-02-17 16:41:58,861] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-02-17 16:41:58,862] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-02-17 16:41:58,869] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,870] INFO Server environment:host.name=aviramco02.corp.amdocs.com (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,870] INFO Server environment:java.version=1.8.0_221 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,871] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,871] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_221\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,871] INFO Server environment:java.class.path=C:\kafka_2.12-2.2.1\libs\activation-1.1.1.jar;C:\kafka_2.12-2.2.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.12-2.2.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.12-2.2.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.12-2.2.1\libs\connect-api-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-basic-auth-extension-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-file-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-json-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-runtime-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-transforms-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\guava-20.0.jar;C:\kafka_2.12-2.2.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-datatype-jdk8-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.12-2.2.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-1.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.12-2.2.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.12-2.2.1\libs\jersey-client-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-common-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-server-2.27.jar;C:\kafka_2.12-2.2.1\libs\jetty-client-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-continuation-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-http-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-io-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-security-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-server-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlet-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlets-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-util-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.12-2.2.1\libs\kafka-clients-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-log4j-appender-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-examples-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-scala_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-test-utils-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-tools-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar.asc;C:\kafka_2.12-2.2.1\libs\log4j-1.2.17.jar;C:\kafka_2.12-2.2.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.12-2.2.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.12-2.2.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.12-2.2.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.12-2.2.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\reflections-0.9.11.jar;C:\kafka_2.12-2.2.1\libs\rocksdbjni-5.15.10.jar;C:\kafka_2.12-2.2.1\libs\scala-library-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\scala-logging_2.12-3.9.0.jar;C:\kafka_2.12-2.2.1\libs\scala-reflect-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.12-2.2.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.12-2.2.1\libs\zkclient-0.11.jar;C:\kafka_2.12-2.2.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.12-2.2.1\libs\zstd-jni-1.3.8-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,875] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_221\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;c:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files\Perforce\;C:\Program Files (x86)\Symantec\VIP Access Client\;C:\Program Files\Git\cmd;C:\apache-maven-3.6.1\bin;C:\Program Files\Redis\;C:\Program Files\Java\jdk1.8.0_221\bin;C:\Program Files\nodejs\;C:\apache-maven-3.6.1\bin;C:\Program Files (x86)\Brackets\command;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\TortoiseGit\bin;C:\Users\aviramco\AppData\Roaming\Cloud Foundry;C:\apache-zookeeper-3.5.5-bin\bin;C:\Users\aviramco\AppData\Local\Microsoft\WindowsApps;;C:\Users\aviramco\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\aviramco\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,876] INFO Server environment:java.io.tmpdir=C:\Users\aviramco\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,877] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,878] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,878] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,879] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,879] INFO Server environment:user.name=aviramco (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,882] INFO Server environment:user.home=C:\Users\aviramco (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,883] INFO Server environment:user.dir=C:\kafka_2.12-2.2.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,893] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,893] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,894] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:41:58,911] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-02-17 16:41:58,913] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-17 16:41:58,914] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at sun.nio.ch.Net.bind0(Native Method)
	at sun.nio.ch.Net.bind(Net.java:433)
	at sun.nio.ch.Net.bind(Net.java:425)
	at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
	at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:67)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:120)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:89)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:55)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:119)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:81)
[2020-02-17 16:42:17,465] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-02-17 16:42:17,467] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-17 16:42:17,468] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-17 16:42:17,468] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-17 16:42:17,468] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-02-17 16:42:17,479] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-02-17 16:42:17,479] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-02-17 16:42:17,487] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,487] INFO Server environment:host.name=aviramco02.corp.amdocs.com (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,488] INFO Server environment:java.version=1.8.0_221 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,488] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,488] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_221\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,489] INFO Server environment:java.class.path=C:\kafka_2.12-2.2.1\libs\activation-1.1.1.jar;C:\kafka_2.12-2.2.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.12-2.2.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.12-2.2.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.12-2.2.1\libs\connect-api-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-basic-auth-extension-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-file-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-json-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-runtime-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-transforms-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\guava-20.0.jar;C:\kafka_2.12-2.2.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-datatype-jdk8-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.12-2.2.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-1.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.12-2.2.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.12-2.2.1\libs\jersey-client-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-common-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-server-2.27.jar;C:\kafka_2.12-2.2.1\libs\jetty-client-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-continuation-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-http-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-io-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-security-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-server-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlet-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlets-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-util-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.12-2.2.1\libs\kafka-clients-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-log4j-appender-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-examples-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-scala_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-test-utils-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-tools-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar.asc;C:\kafka_2.12-2.2.1\libs\log4j-1.2.17.jar;C:\kafka_2.12-2.2.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.12-2.2.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.12-2.2.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.12-2.2.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.12-2.2.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\reflections-0.9.11.jar;C:\kafka_2.12-2.2.1\libs\rocksdbjni-5.15.10.jar;C:\kafka_2.12-2.2.1\libs\scala-library-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\scala-logging_2.12-3.9.0.jar;C:\kafka_2.12-2.2.1\libs\scala-reflect-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.12-2.2.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.12-2.2.1\libs\zkclient-0.11.jar;C:\kafka_2.12-2.2.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.12-2.2.1\libs\zstd-jni-1.3.8-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,492] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_221\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;c:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files\Perforce\;C:\Program Files (x86)\Symantec\VIP Access Client\;C:\Program Files\Git\cmd;C:\apache-maven-3.6.1\bin;C:\Program Files\Redis\;C:\Program Files\Java\jdk1.8.0_221\bin;C:\Program Files\nodejs\;C:\apache-maven-3.6.1\bin;C:\Program Files (x86)\Brackets\command;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\TortoiseGit\bin;C:\Users\aviramco\AppData\Roaming\Cloud Foundry;C:\apache-zookeeper-3.5.5-bin\bin;C:\Users\aviramco\AppData\Local\Microsoft\WindowsApps;;C:\Users\aviramco\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\aviramco\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,493] INFO Server environment:java.io.tmpdir=C:\Users\aviramco\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,494] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,497] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,497] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,498] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,499] INFO Server environment:user.name=aviramco (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,500] INFO Server environment:user.home=C:\Users\aviramco (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,500] INFO Server environment:user.dir=C:\kafka_2.12-2.2.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,510] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,511] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,512] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:17,527] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-02-17 16:42:17,529] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-17 16:42:23,963] INFO Expiring session 0x100155b9b710003, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:23,964] INFO Processed session termination for sessionid: 0x100155b9b710003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:42:23,965] INFO Creating new log file: log.f0 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-02-17 16:42:38,666] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-02-17 16:42:39,126] INFO starting (kafka.server.KafkaServer)
[2020-02-17 16:42:39,127] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-02-17 16:42:39,143] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 16:42:39,149] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:42:39,149] INFO Client environment:host.name=aviramco02.corp.amdocs.com (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:42:39,149] INFO Client environment:java.version=1.8.0_221 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:42:39,150] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:42:39,150] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_221\jre (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:42:39,150] INFO Client environment:java.class.path=C:\kafka_2.12-2.2.1\libs\activation-1.1.1.jar;C:\kafka_2.12-2.2.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.12-2.2.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.12-2.2.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.12-2.2.1\libs\connect-api-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-basic-auth-extension-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-file-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-json-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-runtime-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-transforms-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\guava-20.0.jar;C:\kafka_2.12-2.2.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-datatype-jdk8-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.12-2.2.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-1.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.12-2.2.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.12-2.2.1\libs\jersey-client-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-common-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-server-2.27.jar;C:\kafka_2.12-2.2.1\libs\jetty-client-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-continuation-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-http-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-io-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-security-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-server-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlet-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlets-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-util-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.12-2.2.1\libs\kafka-clients-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-log4j-appender-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-examples-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-scala_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-test-utils-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-tools-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar.asc;C:\kafka_2.12-2.2.1\libs\log4j-1.2.17.jar;C:\kafka_2.12-2.2.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.12-2.2.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.12-2.2.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.12-2.2.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.12-2.2.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\reflections-0.9.11.jar;C:\kafka_2.12-2.2.1\libs\rocksdbjni-5.15.10.jar;C:\kafka_2.12-2.2.1\libs\scala-library-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\scala-logging_2.12-3.9.0.jar;C:\kafka_2.12-2.2.1\libs\scala-reflect-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.12-2.2.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.12-2.2.1\libs\zkclient-0.11.jar;C:\kafka_2.12-2.2.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.12-2.2.1\libs\zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:42:39,153] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_221\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;c:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files\Perforce\;C:\Program Files (x86)\Symantec\VIP Access Client\;C:\Program Files\Git\cmd;C:\apache-maven-3.6.1\bin;C:\Program Files\Redis\;C:\Program Files\Java\jdk1.8.0_221\bin;C:\Program Files\nodejs\;C:\apache-maven-3.6.1\bin;C:\Program Files (x86)\Brackets\command;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\TortoiseGit\bin;C:\Users\aviramco\AppData\Roaming\Cloud Foundry;C:\apache-zookeeper-3.5.5-bin\bin;C:\Users\aviramco\AppData\Local\Microsoft\WindowsApps;;C:\Users\aviramco\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\aviramco\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:42:39,154] INFO Client environment:java.io.tmpdir=C:\Users\aviramco\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:42:39,157] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:42:39,157] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:42:39,158] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:42:39,159] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:42:39,159] INFO Client environment:user.name=aviramco (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:42:39,159] INFO Client environment:user.home=C:\Users\aviramco (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:42:39,160] INFO Client environment:user.dir=C:\kafka_2.12-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:42:39,162] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2473d930 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:42:39,178] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 16:42:39,179] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-02-17 16:42:39,182] INFO Accepted socket connection from /127.0.0.1:2242 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-17 16:42:39,182] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-02-17 16:42:39,188] INFO Client attempting to establish new session at /127.0.0.1:2242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:39,193] INFO Established session 0x100013fc9bf0000 with negotiated timeout 6000 for client /127.0.0.1:2242 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:42:39,195] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100013fc9bf0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-02-17 16:42:39,199] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 16:42:39,269] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0000 type:create cxid:0x1 zxid:0xf2 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:42:39,282] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0000 type:create cxid:0x2 zxid:0xf3 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:42:39,286] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0000 type:create cxid:0x3 zxid:0xf4 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:42:39,290] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0000 type:create cxid:0x4 zxid:0xf5 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:42:39,295] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0000 type:create cxid:0x5 zxid:0xf6 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:42:39,298] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0000 type:create cxid:0x6 zxid:0xf7 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:42:39,302] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0000 type:create cxid:0x7 zxid:0xf8 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:42:39,305] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0000 type:create cxid:0x8 zxid:0xf9 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:42:39,310] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0000 type:create cxid:0x9 zxid:0xfa txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:42:39,313] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0000 type:create cxid:0xa zxid:0xfb txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:42:39,316] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0000 type:create cxid:0xb zxid:0xfc txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:42:39,319] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0000 type:create cxid:0xc zxid:0xfd txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:42:39,322] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0000 type:create cxid:0xd zxid:0xfe txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:42:39,479] INFO Cluster ID = XRps9EzRRcqLJeoulTY-zw (kafka.server.KafkaServer)
[2020-02-17 16:42:39,539] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-17 16:42:39,554] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-17 16:42:39,583] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 16:42:39,583] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 16:42:39,586] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 16:42:39,626] INFO Loading logs. (kafka.log.LogManager)
[2020-02-17 16:42:39,705] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:39,707] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,746] INFO [ProducerStateManager partition=getorderstatus-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-02-17 16:42:39,766] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,772] INFO [ProducerStateManager partition=getorderstatus-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\getorderstatus-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:42:39,783] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 114 ms (kafka.log.Log)
[2020-02-17 16:42:39,800] WARN [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\javainuse-topic-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\javainuse-topic-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580637260499}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:42:39,800] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,808] INFO [ProducerStateManager partition=javainuse-topic-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-02-17 16:42:39,810] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:39,811] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,816] INFO [ProducerStateManager partition=javainuse-topic-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-02-17 16:42:39,823] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,826] INFO [ProducerStateManager partition=javainuse-topic-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\javainuse-topic-0\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:42:39,827] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 33 ms (kafka.log.Log)
[2020-02-17 16:42:39,835] WARN [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\microservicestopic-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\microservicestopic-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580635720904}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:42:39,836] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,842] INFO [ProducerStateManager partition=microservicestopic-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-02-17 16:42:39,843] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:39,844] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,850] INFO [ProducerStateManager partition=microservicestopic-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-02-17 16:42:39,857] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,861] INFO [ProducerStateManager partition=microservicestopic-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\microservicestopic-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:42:39,861] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2020-02-17 16:42:39,870] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:39,871] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,877] INFO [ProducerStateManager partition=sentorderstatus-0] Writing producer snapshot at offset 14 (kafka.log.ProducerStateManager)
[2020-02-17 16:42:39,883] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 14 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,885] INFO [ProducerStateManager partition=sentorderstatus-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\sentorderstatus-0\00000000000000000014.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:42:39,887] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 14 in 22 ms (kafka.log.Log)
[2020-02-17 16:42:39,898] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:39,898] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,909] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,911] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 16:42:39,919] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:39,920] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,930] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,932] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:42:39,940] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:39,941] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,949] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,952] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:42:39,961] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:39,962] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,972] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,976] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-02-17 16:42:39,984] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:39,984] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,994] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:39,997] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 16:42:40,005] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,005] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,014] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,017] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:42:40,026] WARN [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580636397723}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:42:40,026] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,039] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 56 (kafka.log.ProducerStateManager)
[2020-02-17 16:42:40,041] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,042] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,050] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 56 (kafka.log.ProducerStateManager)
[2020-02-17 16:42:40,057] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 56 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,060] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000056.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:42:40,060] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 56 in 40 ms (kafka.log.Log)
[2020-02-17 16:42:40,068] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,068] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,077] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,080] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:42:40,088] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,089] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,097] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,100] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:42:40,110] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,110] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,119] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,121] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:42:40,130] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,131] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,140] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,144] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-02-17 16:42:40,151] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,152] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,161] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,164] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:42:40,172] WARN [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-19\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-19\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580639403388}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:42:40,173] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,180] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-17 16:42:40,182] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,182] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,189] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-17 16:42:40,195] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,198] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-19\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:42:40,199] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 33 ms (kafka.log.Log)
[2020-02-17 16:42:40,207] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,208] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,216] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,220] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:42:40,228] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,228] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,236] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,239] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:42:40,247] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,248] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,256] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,260] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:42:40,267] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,268] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,277] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,280] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:42:40,287] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,288] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,298] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,301] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 16:42:40,309] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,309] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,318] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,321] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:42:40,328] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,329] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,338] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,342] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 16:42:40,350] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,350] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,358] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,361] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:42:40,369] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,370] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,379] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,382] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:42:40,391] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,392] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,400] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,403] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 16:42:40,411] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,411] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,421] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,425] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-02-17 16:42:40,433] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,433] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,442] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,446] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 16:42:40,453] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,454] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,462] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,466] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 16:42:40,473] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,474] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,483] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,486] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:42:40,496] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,496] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,506] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,509] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-02-17 16:42:40,516] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,517] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,525] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,528] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:42:40,534] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,535] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,543] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,546] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:42:40,554] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,555] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,563] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,566] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:42:40,573] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,574] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,582] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,585] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:42:40,593] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,593] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,601] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,604] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:42:40,611] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,612] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,619] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,622] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:42:40,629] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,630] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,638] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,642] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:42:40,648] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,649] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,654] INFO [ProducerStateManager partition=__consumer_offsets-4] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-02-17 16:42:40,661] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,663] INFO [ProducerStateManager partition=__consumer_offsets-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-4\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:42:40,664] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 21 ms (kafka.log.Log)
[2020-02-17 16:42:40,672] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,672] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,681] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,684] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:42:40,691] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,691] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,700] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,703] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:42:40,712] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,713] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,722] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,726] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-02-17 16:42:40,734] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,735] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,744] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,747] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 16:42:40,754] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,755] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,764] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,767] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:42:40,776] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,776] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,785] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,788] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 16:42:40,796] WARN [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580636397725}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:42:40,797] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,804] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-17 16:42:40,806] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,807] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,814] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-17 16:42:40,820] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,823] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:42:40,824] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 33 ms (kafka.log.Log)
[2020-02-17 16:42:40,833] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,833] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,843] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,846] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 16:42:40,853] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,854] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,863] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,866] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 16:42:40,875] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,875] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,885] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,888] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-02-17 16:42:40,897] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,897] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,906] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,910] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-02-17 16:42:40,917] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,917] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,928] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,931] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-02-17 16:42:40,940] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,940] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,949] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,952] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 16:42:40,961] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,961] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,972] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,976] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-02-17 16:42:40,983] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:42:40,983] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,989] INFO [ProducerStateManager partition=__consumer_offsets-9] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-02-17 16:42:40,996] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-02-17 16:42:40,999] INFO [ProducerStateManager partition=__consumer_offsets-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-9\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:42:41,000] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 22 ms (kafka.log.Log)
[2020-02-17 16:42:41,003] INFO Logs loading complete in 1376 ms. (kafka.log.LogManager)
[2020-02-17 16:42:41,016] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-02-17 16:42:41,017] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-02-17 16:42:41,281] INFO Awaiting socket connections on s0.0.0.0:9092. (kafka.network.Acceptor)
[2020-02-17 16:42:41,316] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-02-17 16:42:41,318] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-02-17 16:42:41,348] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:42:41,350] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:42:41,350] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:42:41,350] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:42:41,363] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-02-17 16:42:41,416] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-02-17 16:42:41,439] INFO Stat of the created znode at /brokers/ids/0 is: 255,255,1581950561431,1581950561431,1,0,0,72058967517233152,222,0,255
 (kafka.zk.KafkaZkClient)
[2020-02-17 16:42:41,441] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(aviramco02.corp.amdocs.com,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 255 (kafka.zk.KafkaZkClient)
[2020-02-17 16:42:41,494] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:42:41,497] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:42:41,499] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:42:41,533] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:42:41,535] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:42:41,541] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:41,556] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:4000,blockEndProducerId:4999) by writing to Zk with path version 5 (kafka.coordinator.transaction.ProducerIdManager)
[2020-02-17 16:42:41,600] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-02-17 16:42:41,603] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-02-17 16:42:41,603] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-02-17 16:42:41,659] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-02-17 16:42:41,700] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-02-17 16:42:41,714] INFO Kafka version: 2.2.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-02-17 16:42:41,715] INFO Kafka commitId: 55783d3133a5a49a (org.apache.kafka.common.utils.AppInfoParser)
[2020-02-17 16:42:41,720] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-02-17 16:42:41,838] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0000 type:multi cxid:0x77 zxid:0x102 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:42:41,870] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, javainuse-topic-0, __consumer_offsets-48, microservicestopic-0, __consumer_offsets-19, __consumer_offsets-11, sentorderstatus-0, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, setorderstatus-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, getorderstatus-0, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-02-17 16:42:41,897] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:41,904] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:41,968] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:41,970] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:41,985] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:41,987] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,001] INFO Replica loaded for partition javainuse-topic-0 with initial high watermark 7 (kafka.cluster.Replica)
[2020-02-17 16:42:42,002] INFO [Partition javainuse-topic-0 broker=0] javainuse-topic-0 starts at Leader Epoch 0 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,013] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,014] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,032] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,033] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,047] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,048] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,063] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,064] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,078] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,079] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,091] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 5 (kafka.cluster.Replica)
[2020-02-17 16:42:42,092] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,098] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,099] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,110] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,111] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,121] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,121] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,130] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,131] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,140] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,141] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,150] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,151] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,161] INFO Replica loaded for partition setorderstatus-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,162] INFO [Partition setorderstatus-0 broker=0] setorderstatus-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,172] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,173] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,182] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,183] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,192] INFO Replica loaded for partition microservicestopic-0 with initial high watermark 1 (kafka.cluster.Replica)
[2020-02-17 16:42:42,193] INFO [Partition microservicestopic-0 broker=0] microservicestopic-0 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,198] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,199] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,208] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,209] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,216] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,217] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,226] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 3 (kafka.cluster.Replica)
[2020-02-17 16:42:42,226] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,231] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,232] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,241] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,242] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,249] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,250] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,259] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,260] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,269] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,269] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,279] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,280] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,290] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,291] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,300] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,300] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,310] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,311] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,318] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,319] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,328] INFO Replica loaded for partition sentorderstatus-0 with initial high watermark 14 (kafka.cluster.Replica)
[2020-02-17 16:42:42,329] INFO [Partition sentorderstatus-0 broker=0] sentorderstatus-0 starts at Leader Epoch 0 from offset 14. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,334] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,335] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,344] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,345] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,352] INFO Replica loaded for partition getorderstatus-0 with initial high watermark 2 (kafka.cluster.Replica)
[2020-02-17 16:42:42,353] INFO [Partition getorderstatus-0 broker=0] getorderstatus-0 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,360] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,361] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,369] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,369] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,377] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 5 (kafka.cluster.Replica)
[2020-02-17 16:42:42,378] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,383] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,383] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,393] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 6 (kafka.cluster.Replica)
[2020-02-17 16:42:42,395] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 6. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,399] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,400] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,408] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,408] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,415] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,416] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,425] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,425] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,433] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,433] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,442] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,443] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,450] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,451] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,459] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,459] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,468] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,468] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,476] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,476] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,483] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:42:42,483] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,492] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 56 (kafka.cluster.Replica)
[2020-02-17 16:42:42,493] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 56. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:42:42,508] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,509] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,511] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,512] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,513] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,515] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,516] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,516] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,517] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,518] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,521] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,521] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,523] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,524] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,525] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,525] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,526] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,527] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,528] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,529] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,529] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 20 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,531] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,533] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,533] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,534] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,535] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,535] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,537] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,537] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,538] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,539] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,541] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,543] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,544] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,544] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,546] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,546] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,550] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,551] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,555] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,559] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,559] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,561] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,562] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,564] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,565] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,566] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,567] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,568] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,569] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,569] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,570] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,571] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,572] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,573] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,576] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,577] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,588] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 40 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,590] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,591] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,592] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,593] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,595] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,613] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-1310 with generation 5 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:42:42,622] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 25 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,624] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,625] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,639] INFO [GroupCoordinator 0]: Loading group metadata for group_id with generation 32 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:42:42,640] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,641] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,647] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,648] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,649] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,650] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,650] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,651] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,652] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,653] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,654] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,658] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,660] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,661] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,662] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,663] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,664] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,665] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,666] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,675] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-23580 with generation 5 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:42:42,675] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,676] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,677] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,680] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,682] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,683] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,684] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,685] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,686] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,687] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 32 (__consumer_offsets-13) (reason: Adding new member consumer-1-39390cf4-1b73-43cb-ad5b-2e15d43e882a) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:42:42,687] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,691] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,692] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,693] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,694] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:42:42,697] INFO [GroupCoordinator 0]: Stabilized group group_id generation 33 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:42:42,711] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 33 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:42:42,752] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Rolled new log segment at offset 56 in 8 ms. (kafka.log.Log)
[2020-02-17 16:42:52,625] INFO [GroupCoordinator 0]: Member consumer-1-e40085b9-6351-4c71-87b1-e58a236d3625 in group console-consumer-1310 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:42:52,627] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-1310 in state PreparingRebalance with old generation 5 (__consumer_offsets-4) (reason: removing member consumer-1-e40085b9-6351-4c71-87b1-e58a236d3625 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:42:52,628] INFO [GroupCoordinator 0]: Group console-consumer-1310 with generation 6 is now empty (__consumer_offsets-4) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:42:52,633] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Rolled new log segment at offset 5 in 3 ms. (kafka.log.Log)
[2020-02-17 16:42:52,676] INFO [GroupCoordinator 0]: Member consumer-1-8d80e572-222d-414c-b329-764d5f44c9c2 in group console-consumer-23580 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:42:52,676] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-23580 in state PreparingRebalance with old generation 5 (__consumer_offsets-9) (reason: removing member consumer-1-8d80e572-222d-414c-b329-764d5f44c9c2 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:42:52,678] INFO [GroupCoordinator 0]: Group console-consumer-23580 with generation 6 is now empty (__consumer_offsets-9) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:42:52,683] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Rolled new log segment at offset 5 in 4 ms. (kafka.log.Log)
[2020-02-17 16:42:56,203] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned -> C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:208)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:491)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2014)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2014)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2014)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:582)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
	Suppressed: java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned -> C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:803)
		... 16 more
[2020-02-17 16:42:56,208] INFO [ReplicaManager broker=0] Stopping serving replicas in dir C:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2020-02-17 16:42:56,213] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, javainuse-topic-0, __consumer_offsets-48, microservicestopic-0, __consumer_offsets-19, __consumer_offsets-11, sentorderstatus-0, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, setorderstatus-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, getorderstatus-0, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-02-17 16:42:56,216] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, javainuse-topic-0, __consumer_offsets-48, microservicestopic-0, __consumer_offsets-19, __consumer_offsets-11, sentorderstatus-0, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, setorderstatus-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, getorderstatus-0, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaAlterLogDirsManager)
[2020-02-17 16:42:56,259] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,javainuse-topic-0,__consumer_offsets-48,microservicestopic-0,__consumer_offsets-19,__consumer_offsets-11,sentorderstatus-0,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,setorderstatus-0,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,getorderstatus-0,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2020-02-17 16:42:56,262] INFO Stopping serving logs in dir C:\tmp\kafka-logs (kafka.log.LogManager)
[2020-02-17 16:42:56,263] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2272)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:644)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2020-02-17 16:42:56,268] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2020-02-17 16:42:56,622] WARN Exception causing close of session 0x100013fc9bf0000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-17 16:42:56,624] INFO Closed socket connection for client /127.0.0.1:2242 which had sessionid 0x100013fc9bf0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-17 16:43:02,962] INFO Expiring session 0x100013fc9bf0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:43:02,963] INFO Processed session termination for sessionid: 0x100013fc9bf0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:45:35,328] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:2458 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-17 16:45:35,334] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:2458 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:45:35,337] INFO Established session 0x100013fc9bf0001 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:2458 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:45:35,395] INFO Processed session termination for sessionid: 0x100013fc9bf0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:45:35,398] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:2458 which had sessionid 0x100013fc9bf0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-17 16:46:00,888] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-02-17 16:46:01,377] INFO starting (kafka.server.KafkaServer)
[2020-02-17 16:46:01,379] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-02-17 16:46:01,399] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 16:46:01,406] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:01,407] INFO Client environment:host.name=aviramco02.corp.amdocs.com (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:01,408] INFO Client environment:java.version=1.8.0_221 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:01,409] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:01,410] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_221\jre (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:01,411] INFO Client environment:java.class.path=C:\kafka_2.12-2.2.1\libs\activation-1.1.1.jar;C:\kafka_2.12-2.2.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.12-2.2.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.12-2.2.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.12-2.2.1\libs\connect-api-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-basic-auth-extension-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-file-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-json-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-runtime-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-transforms-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\guava-20.0.jar;C:\kafka_2.12-2.2.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-datatype-jdk8-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.12-2.2.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-1.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.12-2.2.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.12-2.2.1\libs\jersey-client-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-common-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-server-2.27.jar;C:\kafka_2.12-2.2.1\libs\jetty-client-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-continuation-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-http-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-io-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-security-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-server-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlet-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlets-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-util-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.12-2.2.1\libs\kafka-clients-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-log4j-appender-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-examples-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-scala_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-test-utils-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-tools-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar.asc;C:\kafka_2.12-2.2.1\libs\log4j-1.2.17.jar;C:\kafka_2.12-2.2.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.12-2.2.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.12-2.2.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.12-2.2.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.12-2.2.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\reflections-0.9.11.jar;C:\kafka_2.12-2.2.1\libs\rocksdbjni-5.15.10.jar;C:\kafka_2.12-2.2.1\libs\scala-library-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\scala-logging_2.12-3.9.0.jar;C:\kafka_2.12-2.2.1\libs\scala-reflect-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.12-2.2.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.12-2.2.1\libs\zkclient-0.11.jar;C:\kafka_2.12-2.2.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.12-2.2.1\libs\zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:01,415] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_221\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;c:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files\Perforce\;C:\Program Files (x86)\Symantec\VIP Access Client\;C:\Program Files\Git\cmd;C:\apache-maven-3.6.1\bin;C:\Program Files\Redis\;C:\Program Files\Java\jdk1.8.0_221\bin;C:\Program Files\nodejs\;C:\apache-maven-3.6.1\bin;C:\Program Files (x86)\Brackets\command;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\TortoiseGit\bin;C:\Users\aviramco\AppData\Roaming\Cloud Foundry;C:\apache-zookeeper-3.5.5-bin\bin;C:\Users\aviramco\AppData\Local\Microsoft\WindowsApps;;C:\Users\aviramco\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\aviramco\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:01,416] INFO Client environment:java.io.tmpdir=C:\Users\aviramco\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:01,416] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:01,417] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:01,418] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:01,419] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:01,420] INFO Client environment:user.name=aviramco (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:01,424] INFO Client environment:user.home=C:\Users\aviramco (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:01,425] INFO Client environment:user.dir=C:\kafka_2.12-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:01,427] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@769f71a9 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:01,446] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 16:46:01,447] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-02-17 16:46:01,451] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:2493 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-17 16:46:01,451] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-02-17 16:46:01,457] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:2493 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:01,461] INFO Established session 0x100013fc9bf0002 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:2493 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:01,463] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100013fc9bf0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-02-17 16:46:01,469] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 16:46:01,512] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0002 type:create cxid:0x1 zxid:0x107 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:01,525] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0002 type:create cxid:0x2 zxid:0x108 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:01,528] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0002 type:create cxid:0x3 zxid:0x109 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:01,532] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0002 type:create cxid:0x4 zxid:0x10a txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:01,535] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0002 type:create cxid:0x5 zxid:0x10b txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:01,538] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0002 type:create cxid:0x6 zxid:0x10c txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:01,542] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0002 type:create cxid:0x7 zxid:0x10d txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:01,546] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0002 type:create cxid:0x8 zxid:0x10e txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:01,549] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0002 type:create cxid:0x9 zxid:0x10f txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:01,552] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0002 type:create cxid:0xa zxid:0x110 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:01,556] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0002 type:create cxid:0xb zxid:0x111 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:01,559] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0002 type:create cxid:0xc zxid:0x112 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:01,563] INFO Got user-level KeeperException when processing sessionid:0x100013fc9bf0002 type:create cxid:0xd zxid:0x113 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:01,735] INFO Cluster ID = XRps9EzRRcqLJeoulTY-zw (kafka.server.KafkaServer)
[2020-02-17 16:46:01,803] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-17 16:46:01,821] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-17 16:46:01,852] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 16:46:01,852] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 16:46:01,855] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 16:46:01,893] INFO Loading logs. (kafka.log.LogManager)
[2020-02-17 16:46:01,949] WARN [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\getorderstatus-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\getorderstatus-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580657298054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:46:01,951] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:01,992] INFO [ProducerStateManager partition=getorderstatus-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:01,998] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,000] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,007] INFO [ProducerStateManager partition=getorderstatus-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,028] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,032] INFO [ProducerStateManager partition=getorderstatus-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\getorderstatus-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,044] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 122 ms (kafka.log.Log)
[2020-02-17 16:46:02,058] WARN [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\javainuse-topic-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\javainuse-topic-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580637260499}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:46:02,060] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,067] INFO [ProducerStateManager partition=javainuse-topic-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,069] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,070] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,078] INFO [ProducerStateManager partition=javainuse-topic-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,085] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,088] INFO [ProducerStateManager partition=javainuse-topic-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\javainuse-topic-0\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,090] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 36 ms (kafka.log.Log)
[2020-02-17 16:46:02,098] WARN [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\microservicestopic-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\microservicestopic-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580635720904}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:46:02,099] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,106] INFO [ProducerStateManager partition=microservicestopic-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,109] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,110] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,122] INFO [ProducerStateManager partition=microservicestopic-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,129] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,132] INFO [ProducerStateManager partition=microservicestopic-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\microservicestopic-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,133] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 39 ms (kafka.log.Log)
[2020-02-17 16:46:02,141] WARN [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\sentorderstatus-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\sentorderstatus-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580657278012}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:46:02,142] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,150] INFO [ProducerStateManager partition=sentorderstatus-0] Writing producer snapshot at offset 14 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,151] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,152] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,161] INFO [ProducerStateManager partition=sentorderstatus-0] Writing producer snapshot at offset 14 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,167] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 14 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,169] INFO [ProducerStateManager partition=sentorderstatus-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\sentorderstatus-0\00000000000000000014.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,170] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 14 in 33 ms (kafka.log.Log)
[2020-02-17 16:46:02,181] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,181] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,193] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,197] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-02-17 16:46:02,204] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,205] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,213] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,217] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:02,225] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,225] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,233] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,236] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 16:46:02,244] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,245] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,253] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,256] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 16:46:02,264] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,265] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,272] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,276] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 16:46:02,283] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,283] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,292] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,296] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:02,301] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Found file C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2020-02-17 16:46:02,302] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Deleting index files with suffix  for baseFile C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.index (kafka.log.Log)
[2020-02-17 16:46:02,304] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Found file C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2020-02-17 16:46:02,304] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Deleting index files with suffix  for baseFile C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.log (kafka.log.Log)
[2020-02-17 16:46:02,308] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Deleting index files with suffix .swap for baseFile C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.log (kafka.log.Log)
[2020-02-17 16:46:02,316] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,317] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,330] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 56 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,331] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Recovering unflushed segment 56 (kafka.log.Log)
[2020-02-17 16:46:02,332] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 56 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,336] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000056.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,339] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 58 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,345] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 58 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,349] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000058.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,350] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 58 in 51 ms (kafka.log.Log)
[2020-02-17 16:46:02,357] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,358] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,366] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,369] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 16:46:02,376] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,377] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,385] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,388] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:02,396] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,397] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,405] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,409] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:02,416] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,417] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,425] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,428] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:02,435] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,436] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,446] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,449] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:02,458] WARN [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-19\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-19\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580640053488}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:46:02,459] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,465] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,466] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,467] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,474] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,479] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,482] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-19\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,483] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 30 ms (kafka.log.Log)
[2020-02-17 16:46:02,490] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,491] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,499] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,503] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:02,510] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,511] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,518] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,521] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 16:46:02,529] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,529] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,538] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,542] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:46:02,548] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,549] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,557] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,560] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 16:46:02,566] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,567] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,575] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,578] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-02-17 16:46:02,584] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,584] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,592] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,596] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 16:46:02,601] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,602] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,611] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,614] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:02,621] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,622] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,631] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,634] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:02,641] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,641] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,650] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,653] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:02,661] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,661] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,669] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,672] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:02,679] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,680] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,688] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,692] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:46:02,697] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,698] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,708] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,711] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:02,716] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,716] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,726] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,729] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:02,736] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,736] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,745] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,747] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 16:46:02,753] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,754] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,763] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,766] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:02,771] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,772] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,781] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,783] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-02-17 16:46:02,788] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,789] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,797] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,800] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-02-17 16:46:02,805] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,805] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,813] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,816] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-02-17 16:46:02,822] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,823] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,831] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,834] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 16:46:02,839] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,840] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,848] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,850] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-02-17 16:46:02,856] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,857] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,864] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,866] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-17 16:46:02,871] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,872] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,880] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,883] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-02-17 16:46:02,890] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,891] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,898] INFO [ProducerStateManager partition=__consumer_offsets-4] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,899] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Recovering unflushed segment 5 (kafka.log.Log)
[2020-02-17 16:46:02,899] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,903] INFO [ProducerStateManager partition=__consumer_offsets-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-4\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,907] INFO [ProducerStateManager partition=__consumer_offsets-4] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,914] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,917] INFO [ProducerStateManager partition=__consumer_offsets-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-4\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:02,918] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 6 in 33 ms (kafka.log.Log)
[2020-02-17 16:46:02,924] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,925] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,934] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,937] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:46:02,944] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,944] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,953] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,956] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:02,963] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,963] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,970] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,974] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-02-17 16:46:02,980] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,981] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,989] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:02,993] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:02,998] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:02,998] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,007] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,010] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 16:46:03,016] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:03,016] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,025] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,028] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 16:46:03,034] WARN [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580636397725}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:46:03,035] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,042] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:03,044] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:03,046] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,051] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:03,058] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,061] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:03,061] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 31 ms (kafka.log.Log)
[2020-02-17 16:46:03,067] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:03,068] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,077] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,080] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:03,085] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:03,086] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,096] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,099] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:46:03,104] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:03,105] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,115] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,118] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 16:46:03,123] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:03,124] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,133] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,135] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 16:46:03,142] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:03,143] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,151] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,154] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:03,160] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:03,161] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,170] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,173] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:03,179] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:03,179] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,188] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,192] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:03,200] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:03,200] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,208] INFO [ProducerStateManager partition=__consumer_offsets-9] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:03,209] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Recovering unflushed segment 5 (kafka.log.Log)
[2020-02-17 16:46:03,209] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,212] INFO [ProducerStateManager partition=__consumer_offsets-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-9\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:03,215] INFO [ProducerStateManager partition=__consumer_offsets-9] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:03,221] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:03,224] INFO [ProducerStateManager partition=__consumer_offsets-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-9\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:03,225] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 6 in 31 ms (kafka.log.Log)
[2020-02-17 16:46:03,228] INFO Logs loading complete in 1334 ms. (kafka.log.LogManager)
[2020-02-17 16:46:03,237] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-02-17 16:46:03,239] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-02-17 16:46:03,448] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned -> C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:208)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:491)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2014)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2014)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2014)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:582)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
	Suppressed: java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned -> C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:803)
		... 16 more
[2020-02-17 16:46:03,524] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2272)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:644)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2020-02-17 16:46:03,552] INFO Awaiting socket connections on s0.0.0.0:9092. (kafka.network.Acceptor)
[2020-02-17 16:46:03,574] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2272)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:644)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2020-02-17 16:46:03,616] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-02-17 16:46:03,620] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-02-17 16:46:03,633] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2272)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:644)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2020-02-17 16:46:03,674] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:46:03,678] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:46:03,678] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:46:03,678] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:46:03,683] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2272)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:644)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2020-02-17 16:46:03,696] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-02-17 16:46:03,698] INFO [ReplicaManager broker=0] Stopping serving replicas in dir C:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2020-02-17 16:46:03,706] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2020-02-17 16:46:03,709] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2020-02-17 16:46:03,715] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2020-02-17 16:46:03,717] INFO Stopping serving logs in dir C:\tmp\kafka-logs (kafka.log.LogManager)
[2020-02-17 16:46:03,727] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2020-02-17 16:46:04,162] WARN Exception causing close of session 0x100013fc9bf0002: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-17 16:46:04,163] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:2493 which had sessionid 0x100013fc9bf0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-17 16:46:28,346] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-02-17 16:46:28,348] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-17 16:46:28,348] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-17 16:46:28,348] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-17 16:46:28,348] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-02-17 16:46:28,365] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-02-17 16:46:28,365] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-02-17 16:46:28,372] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,372] INFO Server environment:host.name=aviramco02.corp.amdocs.com (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,373] INFO Server environment:java.version=1.8.0_221 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,373] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,373] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_221\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,374] INFO Server environment:java.class.path=C:\kafka_2.12-2.2.1\libs\activation-1.1.1.jar;C:\kafka_2.12-2.2.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.12-2.2.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.12-2.2.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.12-2.2.1\libs\connect-api-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-basic-auth-extension-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-file-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-json-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-runtime-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-transforms-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\guava-20.0.jar;C:\kafka_2.12-2.2.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-datatype-jdk8-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.12-2.2.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-1.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.12-2.2.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.12-2.2.1\libs\jersey-client-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-common-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-server-2.27.jar;C:\kafka_2.12-2.2.1\libs\jetty-client-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-continuation-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-http-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-io-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-security-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-server-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlet-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlets-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-util-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.12-2.2.1\libs\kafka-clients-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-log4j-appender-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-examples-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-scala_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-test-utils-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-tools-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar.asc;C:\kafka_2.12-2.2.1\libs\log4j-1.2.17.jar;C:\kafka_2.12-2.2.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.12-2.2.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.12-2.2.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.12-2.2.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.12-2.2.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\reflections-0.9.11.jar;C:\kafka_2.12-2.2.1\libs\rocksdbjni-5.15.10.jar;C:\kafka_2.12-2.2.1\libs\scala-library-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\scala-logging_2.12-3.9.0.jar;C:\kafka_2.12-2.2.1\libs\scala-reflect-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.12-2.2.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.12-2.2.1\libs\zkclient-0.11.jar;C:\kafka_2.12-2.2.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.12-2.2.1\libs\zstd-jni-1.3.8-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,376] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_221\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;c:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files\Perforce\;C:\Program Files (x86)\Symantec\VIP Access Client\;C:\Program Files\Git\cmd;C:\apache-maven-3.6.1\bin;C:\Program Files\Redis\;C:\Program Files\Java\jdk1.8.0_221\bin;C:\Program Files\nodejs\;C:\apache-maven-3.6.1\bin;C:\Program Files (x86)\Brackets\command;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\TortoiseGit\bin;C:\Users\aviramco\AppData\Roaming\Cloud Foundry;C:\apache-zookeeper-3.5.5-bin\bin;C:\Users\aviramco\AppData\Local\Microsoft\WindowsApps;;C:\Users\aviramco\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\aviramco\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,378] INFO Server environment:java.io.tmpdir=C:\Users\aviramco\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,379] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,379] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,380] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,381] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,382] INFO Server environment:user.name=aviramco (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,382] INFO Server environment:user.home=C:\Users\aviramco (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,385] INFO Server environment:user.dir=C:\kafka_2.12-2.2.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,392] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,393] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,394] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:28,409] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-02-17 16:46:28,411] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-17 16:46:35,976] INFO Expiring session 0x100013fc9bf0002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:35,977] INFO Processed session termination for sessionid: 0x100013fc9bf0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:35,980] INFO Creating new log file: log.114 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-02-17 16:46:45,811] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-02-17 16:46:46,275] INFO starting (kafka.server.KafkaServer)
[2020-02-17 16:46:46,277] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-02-17 16:46:46,294] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 16:46:46,299] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:46,300] INFO Client environment:host.name=aviramco02.corp.amdocs.com (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:46,300] INFO Client environment:java.version=1.8.0_221 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:46,300] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:46,300] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_221\jre (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:46,301] INFO Client environment:java.class.path=C:\kafka_2.12-2.2.1\libs\activation-1.1.1.jar;C:\kafka_2.12-2.2.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.12-2.2.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.12-2.2.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.12-2.2.1\libs\connect-api-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-basic-auth-extension-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-file-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-json-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-runtime-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-transforms-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\guava-20.0.jar;C:\kafka_2.12-2.2.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-datatype-jdk8-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.12-2.2.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-1.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.12-2.2.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.12-2.2.1\libs\jersey-client-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-common-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-server-2.27.jar;C:\kafka_2.12-2.2.1\libs\jetty-client-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-continuation-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-http-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-io-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-security-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-server-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlet-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlets-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-util-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.12-2.2.1\libs\kafka-clients-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-log4j-appender-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-examples-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-scala_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-test-utils-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-tools-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar.asc;C:\kafka_2.12-2.2.1\libs\log4j-1.2.17.jar;C:\kafka_2.12-2.2.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.12-2.2.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.12-2.2.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.12-2.2.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.12-2.2.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\reflections-0.9.11.jar;C:\kafka_2.12-2.2.1\libs\rocksdbjni-5.15.10.jar;C:\kafka_2.12-2.2.1\libs\scala-library-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\scala-logging_2.12-3.9.0.jar;C:\kafka_2.12-2.2.1\libs\scala-reflect-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.12-2.2.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.12-2.2.1\libs\zkclient-0.11.jar;C:\kafka_2.12-2.2.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.12-2.2.1\libs\zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:46,304] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_221\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;c:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files\Perforce\;C:\Program Files (x86)\Symantec\VIP Access Client\;C:\Program Files\Git\cmd;C:\apache-maven-3.6.1\bin;C:\Program Files\Redis\;C:\Program Files\Java\jdk1.8.0_221\bin;C:\Program Files\nodejs\;C:\apache-maven-3.6.1\bin;C:\Program Files (x86)\Brackets\command;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\TortoiseGit\bin;C:\Users\aviramco\AppData\Roaming\Cloud Foundry;C:\apache-zookeeper-3.5.5-bin\bin;C:\Users\aviramco\AppData\Local\Microsoft\WindowsApps;;C:\Users\aviramco\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\aviramco\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:46,308] INFO Client environment:java.io.tmpdir=C:\Users\aviramco\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:46,309] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:46,310] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:46,311] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:46,312] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:46,313] INFO Client environment:user.name=aviramco (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:46,314] INFO Client environment:user.home=C:\Users\aviramco (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:46,314] INFO Client environment:user.dir=C:\kafka_2.12-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:46,316] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2473d930 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:46:46,333] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 16:46:46,334] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-02-17 16:46:46,336] INFO Accepted socket connection from /127.0.0.1:2564 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-17 16:46:46,337] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-02-17 16:46:46,343] INFO Client attempting to establish new session at /127.0.0.1:2564 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:46,350] INFO Established session 0x10001439dad0000 with negotiated timeout 6000 for client /127.0.0.1:2564 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:46,352] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x10001439dad0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-02-17 16:46:46,356] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 16:46:46,399] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0000 type:create cxid:0x1 zxid:0x116 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:46,412] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0000 type:create cxid:0x2 zxid:0x117 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:46,415] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0000 type:create cxid:0x3 zxid:0x118 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:46,418] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0000 type:create cxid:0x4 zxid:0x119 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:46,422] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0000 type:create cxid:0x5 zxid:0x11a txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:46,426] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0000 type:create cxid:0x6 zxid:0x11b txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:46,429] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0000 type:create cxid:0x7 zxid:0x11c txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:46,432] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0000 type:create cxid:0x8 zxid:0x11d txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:46,435] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0000 type:create cxid:0x9 zxid:0x11e txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:46,438] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0000 type:create cxid:0xa zxid:0x11f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:46,442] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0000 type:create cxid:0xb zxid:0x120 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:46,445] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0000 type:create cxid:0xc zxid:0x121 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:46,448] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0000 type:create cxid:0xd zxid:0x122 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:46:46,598] INFO Cluster ID = XRps9EzRRcqLJeoulTY-zw (kafka.server.KafkaServer)
[2020-02-17 16:46:46,656] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-17 16:46:46,672] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-17 16:46:46,702] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 16:46:46,702] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 16:46:46,706] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 16:46:46,745] INFO Loading logs. (kafka.log.LogManager)
[2020-02-17 16:46:46,796] WARN [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\getorderstatus-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\getorderstatus-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580657298054}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:46:46,797] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:46,836] INFO [ProducerStateManager partition=getorderstatus-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:46,843] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:46,844] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:46,849] INFO [ProducerStateManager partition=getorderstatus-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:46,867] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:46,870] INFO [ProducerStateManager partition=getorderstatus-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\getorderstatus-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:46,880] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 107 ms (kafka.log.Log)
[2020-02-17 16:46:46,891] WARN [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\javainuse-topic-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\javainuse-topic-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580637260499}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:46:46,892] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:46,898] INFO [ProducerStateManager partition=javainuse-topic-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:46,900] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:46,901] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:46,909] INFO [ProducerStateManager partition=javainuse-topic-0] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:46,914] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:46,917] INFO [ProducerStateManager partition=javainuse-topic-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\javainuse-topic-0\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:46,918] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 31 ms (kafka.log.Log)
[2020-02-17 16:46:46,928] WARN [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\microservicestopic-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\microservicestopic-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580635720904}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:46:46,929] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:46,935] INFO [ProducerStateManager partition=microservicestopic-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:46,937] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:46,938] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:46,944] INFO [ProducerStateManager partition=microservicestopic-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:46,950] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:46,953] INFO [ProducerStateManager partition=microservicestopic-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\microservicestopic-0\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:46,955] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 31 ms (kafka.log.Log)
[2020-02-17 16:46:46,962] WARN [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\sentorderstatus-0\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\sentorderstatus-0\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580657278012}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:46:46,963] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:46,970] INFO [ProducerStateManager partition=sentorderstatus-0] Writing producer snapshot at offset 14 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:46,972] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:46,973] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:46,979] INFO [ProducerStateManager partition=sentorderstatus-0] Writing producer snapshot at offset 14 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:46,985] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 14 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:46,987] INFO [ProducerStateManager partition=sentorderstatus-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\sentorderstatus-0\00000000000000000014.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:46,988] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 14 in 29 ms (kafka.log.Log)
[2020-02-17 16:46:46,996] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:46,996] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,001] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,003] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:46:47,011] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,011] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,016] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,020] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:46:47,027] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,027] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,033] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,036] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:46:47,044] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,044] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,050] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,052] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:46:47,059] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,059] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,064] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,067] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:46:47,072] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,073] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,078] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,081] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:46:47,086] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Found file C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2020-02-17 16:46:47,087] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Deleting index files with suffix  for baseFile C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.index (kafka.log.Log)
[2020-02-17 16:46:47,089] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Found file C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2020-02-17 16:46:47,089] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Deleting index files with suffix  for baseFile C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.log (kafka.log.Log)
[2020-02-17 16:46:47,092] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Deleting index files with suffix .swap for baseFile C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.log (kafka.log.Log)
[2020-02-17 16:46:47,098] WARN [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000056.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000056.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1581950562825}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:46:47,099] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 56 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,102] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000056.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,105] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 58 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,107] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,108] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,119] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 56 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,120] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Recovering unflushed segment 56 (kafka.log.Log)
[2020-02-17 16:46:47,120] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 56 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,124] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000056.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,127] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 58 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,131] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 58 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,135] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000058.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,136] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 58 in 51 ms (kafka.log.Log)
[2020-02-17 16:46:47,141] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,142] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,146] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,149] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-02-17 16:46:47,154] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,156] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,162] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,165] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-17 16:46:47,170] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,171] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,177] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,179] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:46:47,185] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,186] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,192] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,194] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:46:47,200] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,200] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,205] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,209] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:46:47,214] WARN [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-19\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-19\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580640053488}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:46:47,215] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,221] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,223] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,223] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,229] INFO [ProducerStateManager partition=__consumer_offsets-19] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,234] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,237] INFO [ProducerStateManager partition=__consumer_offsets-19] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-19\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,238] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 6 in 27 ms (kafka.log.Log)
[2020-02-17 16:46:47,244] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,244] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,250] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,252] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:46:47,259] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,260] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,265] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,268] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:46:47,273] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,274] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,281] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,284] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-17 16:46:47,290] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,290] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,296] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,299] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:46:47,305] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,306] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,311] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,314] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:46:47,319] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,320] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,325] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,329] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:46:47,335] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,335] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,341] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,344] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:46:47,350] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,350] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,357] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,360] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-17 16:46:47,365] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,366] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,371] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,374] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:46:47,379] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,380] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,385] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,388] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:46:47,393] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,394] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,400] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,402] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:46:47,409] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,409] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,415] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,418] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-17 16:46:47,424] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,424] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,430] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,433] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:46:47,439] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,439] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,447] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,454] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 16:46:47,464] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,465] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,472] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,475] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:46:47,481] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,482] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,487] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,491] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:46:47,497] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,497] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,503] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,506] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:46:47,512] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,512] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,518] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,521] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:46:47,528] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,529] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,534] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,538] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-17 16:46:47,543] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,544] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,549] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,552] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:46:47,558] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,559] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,565] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,568] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-17 16:46:47,574] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,575] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,580] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,583] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:46:47,592] WARN [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-4\00000000000000000005.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-4\00000000000000000005.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1581950572629}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:46:47,592] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,597] INFO [ProducerStateManager partition=__consumer_offsets-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-4\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,599] INFO [ProducerStateManager partition=__consumer_offsets-4] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,602] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,602] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,609] INFO [ProducerStateManager partition=__consumer_offsets-4] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,610] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Recovering unflushed segment 5 (kafka.log.Log)
[2020-02-17 16:46:47,611] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,615] INFO [ProducerStateManager partition=__consumer_offsets-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-4\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,618] INFO [ProducerStateManager partition=__consumer_offsets-4] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,624] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,627] INFO [ProducerStateManager partition=__consumer_offsets-4] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-4\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,628] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 6 in 42 ms (kafka.log.Log)
[2020-02-17 16:46:47,634] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,634] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,640] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,643] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:46:47,648] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,648] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,653] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,656] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:46:47,661] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,662] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,667] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,670] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:46:47,676] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,676] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,683] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,686] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-17 16:46:47,691] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,691] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,697] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,701] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-17 16:46:47,706] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,706] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,713] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,716] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-17 16:46:47,720] WARN [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000000.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000000.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1580636397725}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:46:47,721] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,727] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,729] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,729] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,736] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,742] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,745] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,746] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 29 ms (kafka.log.Log)
[2020-02-17 16:46:47,751] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,751] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,757] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,761] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-17 16:46:47,766] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,767] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,773] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,776] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-17 16:46:47,782] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,783] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,788] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,791] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-17 16:46:47,797] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,798] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,803] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,806] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:46:47,811] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,812] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,819] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,822] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-17 16:46:47,827] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,827] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,833] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,836] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:46:47,842] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,843] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,849] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,853] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2020-02-17 16:46:47,860] WARN [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Found a corrupted index file corresponding to log file C:\tmp\kafka-logs\__consumer_offsets-9\00000000000000000005.log due to Corrupt time index found, time index file (C:\tmp\kafka-logs\__consumer_offsets-9\00000000000000000005.timeindex) has non-zero size but the last timestamp is 0 which is less than the first timestamp 1581950572678}, recovering segment and rebuilding index files... (kafka.log.Log)
[2020-02-17 16:46:47,861] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,866] INFO [ProducerStateManager partition=__consumer_offsets-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-9\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,868] INFO [ProducerStateManager partition=__consumer_offsets-9] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,870] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 16:46:47,870] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,878] INFO [ProducerStateManager partition=__consumer_offsets-9] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,880] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Recovering unflushed segment 5 (kafka.log.Log)
[2020-02-17 16:46:47,881] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,885] INFO [ProducerStateManager partition=__consumer_offsets-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-9\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,887] INFO [ProducerStateManager partition=__consumer_offsets-9] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,894] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2020-02-17 16:46:47,898] INFO [ProducerStateManager partition=__consumer_offsets-9] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-9\00000000000000000006.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 16:46:47,899] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 6 in 45 ms (kafka.log.Log)
[2020-02-17 16:46:47,902] INFO Logs loading complete in 1156 ms. (kafka.log.LogManager)
[2020-02-17 16:46:47,915] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-02-17 16:46:47,917] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-02-17 16:46:48,123] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned -> C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:806)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:208)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:491)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2014)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2014)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2014)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:582)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
	Suppressed: java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned -> C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:803)
		... 16 more
[2020-02-17 16:46:48,195] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2272)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:644)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2020-02-17 16:46:48,246] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2272)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:644)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2020-02-17 16:46:48,259] INFO Awaiting socket connections on s0.0.0.0:9092. (kafka.network.Acceptor)
[2020-02-17 16:46:48,294] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2272)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:644)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2020-02-17 16:46:48,338] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-02-17 16:46:48,342] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2272)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:644)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2020-02-17 16:46:48,342] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-02-17 16:46:48,383] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2272)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:644)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2020-02-17 16:46:48,394] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:46:48,396] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:46:48,396] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:46:48,399] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:46:48,415] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-02-17 16:46:48,417] INFO [ReplicaManager broker=0] Stopping serving replicas in dir C:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2020-02-17 16:46:48,420] ERROR Failed to clean up log for __consumer_offsets-13 in dir C:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process.

	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:86)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:102)
	at sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:269)
	at sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:108)
	at java.nio.file.Files.deleteIfExists(Files.java:1165)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2272)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:644)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:421)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:537)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:512)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:511)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:511)
	at kafka.log.Cleaner.clean(LogCleaner.scala:489)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:350)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:319)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:300)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2020-02-17 16:46:48,423] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaFetcherManager)
[2020-02-17 16:46:48,427] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set() (kafka.server.ReplicaAlterLogDirsManager)
[2020-02-17 16:46:48,433] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory C:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2020-02-17 16:46:48,435] INFO Stopping serving logs in dir C:\tmp\kafka-logs (kafka.log.LogManager)
[2020-02-17 16:46:48,441] ERROR Shutdown broker because all log dirs in C:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2020-02-17 16:46:48,803] WARN Exception causing close of session 0x10001439dad0000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-17 16:46:48,804] INFO Closed socket connection for client /127.0.0.1:2564 which had sessionid 0x10001439dad0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-17 16:46:56,962] INFO Expiring session 0x10001439dad0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:46:56,963] INFO Processed session termination for sessionid: 0x10001439dad0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:47:37,368] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-02-17 16:47:37,806] INFO starting (kafka.server.KafkaServer)
[2020-02-17 16:47:37,807] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-02-17 16:47:37,827] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 16:47:37,833] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:47:37,834] INFO Client environment:host.name=aviramco02.corp.amdocs.com (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:47:37,835] INFO Client environment:java.version=1.8.0_221 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:47:37,840] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:47:37,840] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_221\jre (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:47:37,841] INFO Client environment:java.class.path=C:\kafka_2.12-2.2.1\libs\activation-1.1.1.jar;C:\kafka_2.12-2.2.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.12-2.2.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.12-2.2.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.12-2.2.1\libs\connect-api-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-basic-auth-extension-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-file-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-json-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-runtime-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-transforms-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\guava-20.0.jar;C:\kafka_2.12-2.2.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-datatype-jdk8-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.12-2.2.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-1.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.12-2.2.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.12-2.2.1\libs\jersey-client-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-common-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-server-2.27.jar;C:\kafka_2.12-2.2.1\libs\jetty-client-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-continuation-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-http-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-io-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-security-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-server-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlet-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlets-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-util-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.12-2.2.1\libs\kafka-clients-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-log4j-appender-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-examples-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-scala_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-test-utils-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-tools-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar.asc;C:\kafka_2.12-2.2.1\libs\log4j-1.2.17.jar;C:\kafka_2.12-2.2.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.12-2.2.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.12-2.2.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.12-2.2.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.12-2.2.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\reflections-0.9.11.jar;C:\kafka_2.12-2.2.1\libs\rocksdbjni-5.15.10.jar;C:\kafka_2.12-2.2.1\libs\scala-library-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\scala-logging_2.12-3.9.0.jar;C:\kafka_2.12-2.2.1\libs\scala-reflect-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.12-2.2.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.12-2.2.1\libs\zkclient-0.11.jar;C:\kafka_2.12-2.2.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.12-2.2.1\libs\zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:47:37,844] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_221\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;c:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files\Perforce\;C:\Program Files (x86)\Symantec\VIP Access Client\;C:\Program Files\Git\cmd;C:\apache-maven-3.6.1\bin;C:\Program Files\Redis\;C:\Program Files\Java\jdk1.8.0_221\bin;C:\Program Files\nodejs\;C:\apache-maven-3.6.1\bin;C:\Program Files (x86)\Brackets\command;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\TortoiseGit\bin;C:\Users\aviramco\AppData\Roaming\Cloud Foundry;C:\apache-zookeeper-3.5.5-bin\bin;C:\Users\aviramco\AppData\Local\Microsoft\WindowsApps;;C:\Users\aviramco\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\aviramco\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:47:37,845] INFO Client environment:java.io.tmpdir=C:\Users\aviramco\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:47:37,846] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:47:37,847] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:47:37,849] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:47:37,853] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:47:37,854] INFO Client environment:user.name=aviramco (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:47:37,856] INFO Client environment:user.home=C:\Users\aviramco (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:47:37,857] INFO Client environment:user.dir=C:\kafka_2.12-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:47:37,859] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@769f71a9 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 16:47:37,876] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 16:47:37,877] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-02-17 16:47:37,880] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:2638 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-17 16:47:37,880] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-02-17 16:47:37,885] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:2638 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:47:37,887] INFO Established session 0x10001439dad0001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:2638 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:47:37,890] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x10001439dad0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-02-17 16:47:37,894] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 16:47:37,933] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0001 type:create cxid:0x1 zxid:0x125 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:47:37,945] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0001 type:create cxid:0x2 zxid:0x126 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:47:37,948] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0001 type:create cxid:0x3 zxid:0x127 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:47:37,951] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0001 type:create cxid:0x4 zxid:0x128 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:47:37,954] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0001 type:create cxid:0x5 zxid:0x129 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:47:37,958] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0001 type:create cxid:0x6 zxid:0x12a txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:47:37,963] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0001 type:create cxid:0x7 zxid:0x12b txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:47:37,966] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0001 type:create cxid:0x8 zxid:0x12c txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:47:37,970] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0001 type:create cxid:0x9 zxid:0x12d txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:47:37,974] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0001 type:create cxid:0xa zxid:0x12e txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:47:37,978] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0001 type:create cxid:0xb zxid:0x12f txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:47:37,981] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0001 type:create cxid:0xc zxid:0x130 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:47:37,984] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0001 type:create cxid:0xd zxid:0x131 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:47:38,121] INFO Cluster ID = XRps9EzRRcqLJeoulTY-zw (kafka.server.KafkaServer)
[2020-02-17 16:47:38,134] WARN No meta.properties file under dir C:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-02-17 16:47:38,188] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-17 16:47:38,207] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-17 16:47:38,239] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 16:47:38,239] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 16:47:38,245] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 16:47:38,275] INFO Log directory C:\tmp\kafka-logs not found, creating it. (kafka.log.LogManager)
[2020-02-17 16:47:38,286] INFO Loading logs. (kafka.log.LogManager)
[2020-02-17 16:47:38,295] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2020-02-17 16:47:38,312] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-02-17 16:47:38,316] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-02-17 16:47:38,560] INFO Awaiting socket connections on s0.0.0.0:9092. (kafka.network.Acceptor)
[2020-02-17 16:47:38,591] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-02-17 16:47:38,593] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-02-17 16:47:38,616] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:47:38,618] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:47:38,618] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:47:38,622] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:47:38,631] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-02-17 16:47:38,675] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-02-17 16:47:38,706] INFO Stat of the created znode at /brokers/ids/0 is: 306,306,1581950858685,1581950858685,1,0,0,72058983957725185,222,0,306
 (kafka.zk.KafkaZkClient)
[2020-02-17 16:47:38,707] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(aviramco02.corp.amdocs.com,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 306 (kafka.zk.KafkaZkClient)
[2020-02-17 16:47:38,710] WARN No meta.properties file under dir C:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-02-17 16:47:38,755] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:47:38,759] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:47:38,759] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 16:47:38,789] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:47:38,791] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:47:38,797] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:38,811] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:5000,blockEndProducerId:5999) by writing to Zk with path version 6 (kafka.coordinator.transaction.ProducerIdManager)
[2020-02-17 16:47:38,846] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-02-17 16:47:38,849] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-02-17 16:47:38,849] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-02-17 16:47:38,901] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-02-17 16:47:38,930] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-02-17 16:47:38,938] INFO Kafka version: 2.2.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-02-17 16:47:38,940] INFO Kafka commitId: 55783d3133a5a49a (org.apache.kafka.common.utils.AppInfoParser)
[2020-02-17 16:47:38,944] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-02-17 16:47:39,014] INFO Got user-level KeeperException when processing sessionid:0x10001439dad0001 type:multi cxid:0x7a zxid:0x135 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:47:39,043] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, javainuse-topic-0, __consumer_offsets-48, microservicestopic-0, __consumer_offsets-19, __consumer_offsets-11, sentorderstatus-0, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, setorderstatus-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, getorderstatus-0, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-02-17 16:47:39,098] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,111] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2020-02-17 16:47:39,113] INFO Created log for partition __consumer_offsets-0 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,115] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-02-17 16:47:39,118] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,124] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,154] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,159] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-02-17 16:47:39,160] INFO Created log for partition __consumer_offsets-29 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,162] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-02-17 16:47:39,163] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,163] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,173] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,177] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 16:47:39,178] INFO Created log for partition __consumer_offsets-48 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,179] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-02-17 16:47:39,179] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,180] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,192] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,194] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 16:47:39,196] INFO Created log for partition javainuse-topic-0 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,197] INFO [Partition javainuse-topic-0 broker=0] No checkpointed highwatermark is found for partition javainuse-topic-0 (kafka.cluster.Partition)
[2020-02-17 16:47:39,200] INFO Replica loaded for partition javainuse-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,202] INFO [Partition javainuse-topic-0 broker=0] javainuse-topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,216] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,219] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 16:47:39,221] INFO Created log for partition __consumer_offsets-10 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,224] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-02-17 16:47:39,224] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,225] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,236] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,240] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-02-17 16:47:39,243] INFO Created log for partition __consumer_offsets-45 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,244] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-02-17 16:47:39,244] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,245] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,259] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,263] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-02-17 16:47:39,264] INFO Created log for partition __consumer_offsets-26 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,266] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-02-17 16:47:39,269] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,270] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,290] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,294] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-02-17 16:47:39,295] INFO Created log for partition __consumer_offsets-7 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,297] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-02-17 16:47:39,297] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,302] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,318] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,322] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-02-17 16:47:39,324] INFO Created log for partition __consumer_offsets-42 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,325] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-02-17 16:47:39,326] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,327] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,342] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,345] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-02-17 16:47:39,347] INFO Created log for partition __consumer_offsets-4 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,349] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-02-17 16:47:39,349] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,353] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,366] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,369] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-02-17 16:47:39,371] INFO Created log for partition __consumer_offsets-23 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,374] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-02-17 16:47:39,374] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,375] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,386] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,389] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-02-17 16:47:39,390] INFO Created log for partition __consumer_offsets-1 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,393] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,397] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,399] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,413] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,416] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 16:47:39,417] INFO Created log for partition __consumer_offsets-20 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,419] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-02-17 16:47:39,419] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,420] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,431] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,434] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-02-17 16:47:39,435] INFO Created log for partition __consumer_offsets-39 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,436] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-02-17 16:47:39,437] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,437] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,448] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,451] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-02-17 16:47:39,452] INFO Created log for partition __consumer_offsets-17 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,453] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-02-17 16:47:39,454] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,454] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,468] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,472] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 16:47:39,482] INFO Created log for partition __consumer_offsets-36 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,484] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-02-17 16:47:39,484] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,485] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,502] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,506] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 16:47:39,507] INFO Created log for partition setorderstatus-0 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,510] INFO [Partition setorderstatus-0 broker=0] No checkpointed highwatermark is found for partition setorderstatus-0 (kafka.cluster.Partition)
[2020-02-17 16:47:39,511] INFO Replica loaded for partition setorderstatus-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,511] INFO [Partition setorderstatus-0 broker=0] setorderstatus-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,523] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,526] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 16:47:39,534] INFO Created log for partition __consumer_offsets-14 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,535] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-02-17 16:47:39,535] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,540] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,551] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,553] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-02-17 16:47:39,554] INFO Created log for partition __consumer_offsets-33 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,556] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-02-17 16:47:39,557] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,558] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,567] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,570] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-02-17 16:47:39,571] INFO Created log for partition microservicestopic-0 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,573] INFO [Partition microservicestopic-0 broker=0] No checkpointed highwatermark is found for partition microservicestopic-0 (kafka.cluster.Partition)
[2020-02-17 16:47:39,574] INFO Replica loaded for partition microservicestopic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,574] INFO [Partition microservicestopic-0 broker=0] microservicestopic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,584] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,587] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 16:47:39,588] INFO Created log for partition __consumer_offsets-49 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,590] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-02-17 16:47:39,590] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,591] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,601] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,604] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 16:47:39,605] INFO Created log for partition __consumer_offsets-11 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,608] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-02-17 16:47:39,610] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,611] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,624] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,627] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 16:47:39,628] INFO Created log for partition __consumer_offsets-30 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,629] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-02-17 16:47:39,630] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,630] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,641] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,644] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 16:47:39,645] INFO Created log for partition __consumer_offsets-46 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,646] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-02-17 16:47:39,647] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,647] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,659] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,662] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-17 16:47:39,663] INFO Created log for partition __consumer_offsets-27 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,666] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-02-17 16:47:39,666] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,666] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,678] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,681] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 16:47:39,682] INFO Created log for partition __consumer_offsets-8 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,683] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-02-17 16:47:39,683] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,685] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,703] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,707] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-02-17 16:47:39,711] INFO Created log for partition __consumer_offsets-24 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,713] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-02-17 16:47:39,715] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,716] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,726] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,729] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 16:47:39,730] INFO Created log for partition __consumer_offsets-43 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,731] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-02-17 16:47:39,732] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,733] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,744] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,746] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 16:47:39,748] INFO Created log for partition __consumer_offsets-5 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,748] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-02-17 16:47:39,749] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,750] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,761] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,764] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 16:47:39,764] INFO Created log for partition __consumer_offsets-21 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,766] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-02-17 16:47:39,769] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,775] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,787] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,790] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 16:47:39,793] INFO Created log for partition __consumer_offsets-2 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,794] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-02-17 16:47:39,795] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,796] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,810] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,814] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-02-17 16:47:39,816] INFO Created log for partition __consumer_offsets-40 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,819] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-02-17 16:47:39,820] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,822] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,838] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,842] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-17 16:47:39,843] INFO Created log for partition __consumer_offsets-37 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,845] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-02-17 16:47:39,845] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,846] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,859] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,862] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-02-17 16:47:39,865] INFO Created log for partition __consumer_offsets-18 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,867] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-02-17 16:47:39,869] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,870] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,883] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,887] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-17 16:47:39,889] INFO Created log for partition sentorderstatus-0 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,890] INFO [Partition sentorderstatus-0 broker=0] No checkpointed highwatermark is found for partition sentorderstatus-0 (kafka.cluster.Partition)
[2020-02-17 16:47:39,890] INFO Replica loaded for partition sentorderstatus-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,891] INFO [Partition sentorderstatus-0 broker=0] sentorderstatus-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,903] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,907] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-02-17 16:47:39,910] INFO Created log for partition __consumer_offsets-34 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,912] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-02-17 16:47:39,913] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,917] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,932] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,936] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-17 16:47:39,938] INFO Created log for partition __consumer_offsets-15 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,940] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-02-17 16:47:39,943] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,945] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,962] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,965] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-17 16:47:39,967] INFO Created log for partition getorderstatus-0 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,968] INFO [Partition getorderstatus-0 broker=0] No checkpointed highwatermark is found for partition getorderstatus-0 (kafka.cluster.Partition)
[2020-02-17 16:47:39,969] INFO Replica loaded for partition getorderstatus-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:39,969] INFO [Partition getorderstatus-0 broker=0] getorderstatus-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:39,987] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:39,993] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:47:39,996] INFO Created log for partition __consumer_offsets-12 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:39,998] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-02-17 16:47:39,999] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,001] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,017] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:40,023] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:47:40,026] INFO Created log for partition __consumer_offsets-31 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:40,029] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-02-17 16:47:40,032] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,033] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,056] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:40,064] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 16:47:40,066] INFO Created log for partition __consumer_offsets-9 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:40,067] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-02-17 16:47:40,068] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,071] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,093] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:40,098] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:47:40,100] INFO Created log for partition __consumer_offsets-47 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:40,102] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-02-17 16:47:40,102] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,103] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,121] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:40,127] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:47:40,129] INFO Created log for partition __consumer_offsets-19 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:40,132] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-02-17 16:47:40,134] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,135] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,153] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:40,160] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2020-02-17 16:47:40,161] INFO Created log for partition __consumer_offsets-28 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:40,164] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-02-17 16:47:40,165] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,169] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,184] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:40,188] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-17 16:47:40,190] INFO Created log for partition __consumer_offsets-38 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:40,197] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-02-17 16:47:40,199] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,202] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,216] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:40,220] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-02-17 16:47:40,222] INFO Created log for partition __consumer_offsets-35 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:40,227] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-02-17 16:47:40,230] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,231] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,248] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:40,253] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-02-17 16:47:40,254] INFO Created log for partition __consumer_offsets-6 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:40,256] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-02-17 16:47:40,260] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,264] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,282] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:40,287] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-02-17 16:47:40,289] INFO Created log for partition __consumer_offsets-44 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:40,293] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-02-17 16:47:40,293] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,297] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,318] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:40,321] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-17 16:47:40,323] INFO Created log for partition __consumer_offsets-25 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:40,327] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-02-17 16:47:40,327] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,328] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,346] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:40,350] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2020-02-17 16:47:40,352] INFO Created log for partition __consumer_offsets-16 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:40,357] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-02-17 16:47:40,360] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,362] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,382] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:40,388] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2020-02-17 16:47:40,390] INFO Created log for partition __consumer_offsets-22 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:40,392] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-02-17 16:47:40,392] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,395] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,413] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:40,417] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-02-17 16:47:40,419] INFO Created log for partition __consumer_offsets-41 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:40,421] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-02-17 16:47:40,422] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,424] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,438] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:40,443] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-17 16:47:40,444] INFO Created log for partition __consumer_offsets-32 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:40,447] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-02-17 16:47:40,448] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,452] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,468] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:40,472] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-02-17 16:47:40,474] INFO Created log for partition __consumer_offsets-3 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:40,477] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-02-17 16:47:40,478] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,479] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,496] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 16:47:40,500] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-02-17 16:47:40,503] INFO Created log for partition __consumer_offsets-13 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 16:47:40,504] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-02-17 16:47:40,508] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 16:47:40,509] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 16:47:40,523] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,525] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,527] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,528] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,532] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,533] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,534] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,535] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,539] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,542] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,543] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,544] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,545] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,547] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,551] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 26 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,552] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,554] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,557] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,559] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,562] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,563] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,567] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,568] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,569] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,570] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,576] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,577] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,578] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,579] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,580] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,581] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,582] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,586] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,587] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,592] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,593] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,594] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,597] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,600] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,602] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,603] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,606] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,609] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,610] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,613] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,614] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,615] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,616] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,617] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,618] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,622] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,625] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,626] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,626] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,627] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,628] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,629] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,632] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,634] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,636] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,637] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,638] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,640] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,641] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,644] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,645] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,648] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,649] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,650] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,651] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,652] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,652] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,657] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,658] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,660] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,661] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,663] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,664] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,666] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,668] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,670] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,673] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,674] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,675] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,676] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,681] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,682] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,686] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,687] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,689] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,690] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,692] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,696] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,698] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,700] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,702] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,703] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,704] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 16:47:40,873] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 0 (__consumer_offsets-13) (reason: Adding new member consumer-1-138651ba-28e9-401b-94a9-8141b2c848d7) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:47:40,881] INFO [GroupCoordinator 0]: Stabilized group group_id generation 1 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:47:40,890] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:48:17,382] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:2663 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-17 16:48:17,384] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:2663 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:48:17,389] INFO Established session 0x10001439dad0002 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:2663 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 16:48:17,579] INFO Processed session termination for sessionid: 0x10001439dad0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 16:48:17,583] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:2663 which had sessionid 0x10001439dad0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-17 16:48:56,010] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-10831 in state PreparingRebalance with old generation 0 (__consumer_offsets-44) (reason: Adding new member consumer-1-05c8d1d4-5335-4870-95d5-4f289e246b75) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:48:56,012] INFO [GroupCoordinator 0]: Stabilized group console-consumer-10831 generation 1 (__consumer_offsets-44) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:48:56,018] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-10831 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:50:18,128] INFO [GroupCoordinator 0]: Member consumer-1-138651ba-28e9-401b-94a9-8141b2c848d7 in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:50:18,130] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 1 (__consumer_offsets-13) (reason: removing member consumer-1-138651ba-28e9-401b-94a9-8141b2c848d7 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:50:18,132] INFO [GroupCoordinator 0]: Group group_id with generation 2 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 16:57:38,802] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:00:30,667] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 2 (__consumer_offsets-13) (reason: Adding new member consumer-1-2a30b44b-1379-4295-8fe5-68de7c62918f) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:00:30,697] INFO [GroupCoordinator 0]: Stabilized group group_id generation 3 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:00:30,708] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:07:38,795] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:17:38,796] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:18:09,008] INFO [GroupCoordinator 0]: Member consumer-1-2a30b44b-1379-4295-8fe5-68de7c62918f in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:18:09,009] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 3 (__consumer_offsets-13) (reason: removing member consumer-1-2a30b44b-1379-4295-8fe5-68de7c62918f on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:18:09,017] INFO [GroupCoordinator 0]: Group group_id with generation 4 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:18:54,060] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 4 (__consumer_offsets-13) (reason: Adding new member consumer-1-5d15c939-aa0e-4479-98d3-38c18302dc2d) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:18:54,061] INFO [GroupCoordinator 0]: Stabilized group group_id generation 5 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:18:54,073] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 5 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:19:40,335] INFO [GroupCoordinator 0]: Member consumer-1-5d15c939-aa0e-4479-98d3-38c18302dc2d in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:19:40,336] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 5 (__consumer_offsets-13) (reason: removing member consumer-1-5d15c939-aa0e-4479-98d3-38c18302dc2d on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:19:40,339] INFO [GroupCoordinator 0]: Group group_id with generation 6 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:20:04,107] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 6 (__consumer_offsets-13) (reason: Adding new member consumer-1-b27eee4b-8f64-4a2b-9fd7-de8dd1dad8b8) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:20:04,109] INFO [GroupCoordinator 0]: Stabilized group group_id generation 7 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:20:04,120] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 7 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:20:26,235] INFO [GroupCoordinator 0]: Member consumer-1-b27eee4b-8f64-4a2b-9fd7-de8dd1dad8b8 in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:20:26,236] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 7 (__consumer_offsets-13) (reason: removing member consumer-1-b27eee4b-8f64-4a2b-9fd7-de8dd1dad8b8 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:20:26,238] INFO [GroupCoordinator 0]: Group group_id with generation 8 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:21:01,437] WARN Session 0x10001439dad0001 for server localhost/0:0:0:0:0:0:0:1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1145)
[2020-02-17 17:21:26,450] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-02-17 17:21:26,452] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-17 17:21:26,453] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-17 17:21:26,453] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-17 17:21:26,453] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-02-17 17:21:26,465] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-02-17 17:21:26,466] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-02-17 17:21:26,473] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,474] INFO Server environment:host.name=aviramco02.corp.amdocs.com (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,474] INFO Server environment:java.version=1.8.0_221 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,474] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,474] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_221\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,475] INFO Server environment:java.class.path=C:\kafka_2.12-2.2.1\libs\activation-1.1.1.jar;C:\kafka_2.12-2.2.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.12-2.2.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.12-2.2.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.12-2.2.1\libs\connect-api-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-basic-auth-extension-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-file-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-json-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-runtime-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-transforms-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\guava-20.0.jar;C:\kafka_2.12-2.2.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-datatype-jdk8-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.12-2.2.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-1.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.12-2.2.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.12-2.2.1\libs\jersey-client-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-common-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-server-2.27.jar;C:\kafka_2.12-2.2.1\libs\jetty-client-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-continuation-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-http-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-io-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-security-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-server-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlet-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlets-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-util-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.12-2.2.1\libs\kafka-clients-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-log4j-appender-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-examples-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-scala_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-test-utils-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-tools-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar.asc;C:\kafka_2.12-2.2.1\libs\log4j-1.2.17.jar;C:\kafka_2.12-2.2.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.12-2.2.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.12-2.2.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.12-2.2.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.12-2.2.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\reflections-0.9.11.jar;C:\kafka_2.12-2.2.1\libs\rocksdbjni-5.15.10.jar;C:\kafka_2.12-2.2.1\libs\scala-library-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\scala-logging_2.12-3.9.0.jar;C:\kafka_2.12-2.2.1\libs\scala-reflect-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.12-2.2.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.12-2.2.1\libs\zkclient-0.11.jar;C:\kafka_2.12-2.2.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.12-2.2.1\libs\zstd-jni-1.3.8-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,477] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_221\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;c:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files\Perforce\;C:\Program Files (x86)\Symantec\VIP Access Client\;C:\Program Files\Git\cmd;C:\apache-maven-3.6.1\bin;C:\Program Files\Redis\;C:\Program Files\Java\jdk1.8.0_221\bin;C:\Program Files\nodejs\;C:\apache-maven-3.6.1\bin;C:\Program Files (x86)\Brackets\command;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\TortoiseGit\bin;C:\Users\aviramco\AppData\Roaming\Cloud Foundry;C:\apache-zookeeper-3.5.5-bin\bin;C:\Users\aviramco\AppData\Local\Microsoft\WindowsApps;;C:\Users\aviramco\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\aviramco\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,481] INFO Server environment:java.io.tmpdir=C:\Users\aviramco\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,481] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,482] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,483] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,484] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,484] INFO Server environment:user.name=aviramco (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,485] INFO Server environment:user.home=C:\Users\aviramco (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,485] INFO Server environment:user.dir=C:\kafka_2.12-2.2.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,493] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,493] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,494] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:26,511] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-02-17 17:21:26,513] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-17 17:21:32,964] INFO Expiring session 0x10001439dad0001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:32,966] INFO Processed session termination for sessionid: 0x10001439dad0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:21:32,968] INFO Creating new log file: log.138 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-02-17 17:21:38,356] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-02-17 17:21:38,933] INFO starting (kafka.server.KafkaServer)
[2020-02-17 17:21:38,934] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-02-17 17:21:38,958] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 17:21:38,965] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:21:38,966] INFO Client environment:host.name=aviramco02.corp.amdocs.com (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:21:38,966] INFO Client environment:java.version=1.8.0_221 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:21:38,974] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:21:38,974] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_221\jre (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:21:38,974] INFO Client environment:java.class.path=C:\kafka_2.12-2.2.1\libs\activation-1.1.1.jar;C:\kafka_2.12-2.2.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.12-2.2.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.12-2.2.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.12-2.2.1\libs\connect-api-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-basic-auth-extension-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-file-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-json-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-runtime-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-transforms-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\guava-20.0.jar;C:\kafka_2.12-2.2.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-datatype-jdk8-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.12-2.2.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-1.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.12-2.2.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.12-2.2.1\libs\jersey-client-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-common-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-server-2.27.jar;C:\kafka_2.12-2.2.1\libs\jetty-client-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-continuation-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-http-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-io-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-security-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-server-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlet-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlets-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-util-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.12-2.2.1\libs\kafka-clients-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-log4j-appender-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-examples-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-scala_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-test-utils-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-tools-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar.asc;C:\kafka_2.12-2.2.1\libs\log4j-1.2.17.jar;C:\kafka_2.12-2.2.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.12-2.2.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.12-2.2.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.12-2.2.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.12-2.2.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\reflections-0.9.11.jar;C:\kafka_2.12-2.2.1\libs\rocksdbjni-5.15.10.jar;C:\kafka_2.12-2.2.1\libs\scala-library-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\scala-logging_2.12-3.9.0.jar;C:\kafka_2.12-2.2.1\libs\scala-reflect-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.12-2.2.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.12-2.2.1\libs\zkclient-0.11.jar;C:\kafka_2.12-2.2.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.12-2.2.1\libs\zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:21:38,978] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_221\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;c:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files\Perforce\;C:\Program Files (x86)\Symantec\VIP Access Client\;C:\Program Files\Git\cmd;C:\apache-maven-3.6.1\bin;C:\Program Files\Redis\;C:\Program Files\Java\jdk1.8.0_221\bin;C:\Program Files\nodejs\;C:\apache-maven-3.6.1\bin;C:\Program Files (x86)\Brackets\command;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\TortoiseGit\bin;C:\Users\aviramco\AppData\Roaming\Cloud Foundry;C:\apache-zookeeper-3.5.5-bin\bin;C:\Users\aviramco\AppData\Local\Microsoft\WindowsApps;;C:\Users\aviramco\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\aviramco\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:21:38,982] INFO Client environment:java.io.tmpdir=C:\Users\aviramco\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:21:38,983] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:21:38,984] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:21:38,985] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:21:38,985] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:21:38,986] INFO Client environment:user.name=aviramco (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:21:38,987] INFO Client environment:user.home=C:\Users\aviramco (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:21:38,988] INFO Client environment:user.dir=C:\kafka_2.12-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:21:38,993] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2473d930 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:21:39,017] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 17:21:39,018] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-02-17 17:21:39,022] INFO Accepted socket connection from /127.0.0.1:3147 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-17 17:21:39,022] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-02-17 17:21:39,030] INFO Client attempting to establish new session at /127.0.0.1:3147 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:39,035] INFO Established session 0x1000163a1640000 with negotiated timeout 6000 for client /127.0.0.1:3147 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:21:39,037] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000163a1640000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-02-17 17:21:39,044] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 17:21:39,106] INFO Got user-level KeeperException when processing sessionid:0x1000163a1640000 type:create cxid:0x1 zxid:0x13a txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:21:39,120] INFO Got user-level KeeperException when processing sessionid:0x1000163a1640000 type:create cxid:0x2 zxid:0x13b txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:21:39,123] INFO Got user-level KeeperException when processing sessionid:0x1000163a1640000 type:create cxid:0x3 zxid:0x13c txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:21:39,127] INFO Got user-level KeeperException when processing sessionid:0x1000163a1640000 type:create cxid:0x4 zxid:0x13d txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:21:39,130] INFO Got user-level KeeperException when processing sessionid:0x1000163a1640000 type:create cxid:0x5 zxid:0x13e txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:21:39,134] INFO Got user-level KeeperException when processing sessionid:0x1000163a1640000 type:create cxid:0x6 zxid:0x13f txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:21:39,137] INFO Got user-level KeeperException when processing sessionid:0x1000163a1640000 type:create cxid:0x7 zxid:0x140 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:21:39,140] INFO Got user-level KeeperException when processing sessionid:0x1000163a1640000 type:create cxid:0x8 zxid:0x141 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:21:39,144] INFO Got user-level KeeperException when processing sessionid:0x1000163a1640000 type:create cxid:0x9 zxid:0x142 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:21:39,148] INFO Got user-level KeeperException when processing sessionid:0x1000163a1640000 type:create cxid:0xa zxid:0x143 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:21:39,151] INFO Got user-level KeeperException when processing sessionid:0x1000163a1640000 type:create cxid:0xb zxid:0x144 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:21:39,154] INFO Got user-level KeeperException when processing sessionid:0x1000163a1640000 type:create cxid:0xc zxid:0x145 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:21:39,157] INFO Got user-level KeeperException when processing sessionid:0x1000163a1640000 type:create cxid:0xd zxid:0x146 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:21:39,331] INFO Cluster ID = XRps9EzRRcqLJeoulTY-zw (kafka.server.KafkaServer)
[2020-02-17 17:21:39,407] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-17 17:21:39,426] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-17 17:21:39,462] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 17:21:39,462] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 17:21:39,463] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 17:21:39,508] INFO Loading logs. (kafka.log.LogManager)
[2020-02-17 17:21:39,575] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,578] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,624] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,629] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 87 ms (kafka.log.Log)
[2020-02-17 17:21:39,642] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,643] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,652] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,655] INFO [Log partition=javainuse-topic-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 17:21:39,663] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,664] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,673] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,677] INFO [Log partition=microservicestopic-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 17:21:39,684] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,685] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,697] INFO [ProducerStateManager partition=sentorderstatus-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-02-17 17:21:39,713] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,718] INFO [ProducerStateManager partition=sentorderstatus-0] Loading producer state from snapshot file 'C:\tmp\kafka-logs\sentorderstatus-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 17:21:39,727] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 46 ms (kafka.log.Log)
[2020-02-17 17:21:39,734] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,735] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,743] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,746] INFO [Log partition=setorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 17:21:39,753] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,754] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,762] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,766] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 17:21:39,772] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,773] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,782] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,785] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 17:21:39,792] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,793] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,801] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,804] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 17:21:39,811] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,812] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,820] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,823] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 17:21:39,830] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,830] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,838] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,842] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 17:21:39,848] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,849] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,854] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 12 (kafka.log.ProducerStateManager)
[2020-02-17 17:21:39,861] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,863] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 17:21:39,864] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 12 in 19 ms (kafka.log.Log)
[2020-02-17 17:21:39,870] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,870] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,879] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,882] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 17:21:39,889] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,889] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,898] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,901] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 17:21:39,907] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,907] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,915] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,919] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 17:21:39,925] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,926] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,934] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,937] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 17:21:39,944] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,945] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,953] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,956] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 17:21:39,962] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,962] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,971] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,975] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 17:21:39,981] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:39,982] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,992] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:39,996] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 17:21:40,003] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,003] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,012] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,015] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 17:21:40,021] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,022] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,030] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,033] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 17:21:40,040] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,041] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,049] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,052] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 17:21:40,060] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,060] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,069] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,072] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 17:21:40,079] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,079] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,088] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,091] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 17:21:40,098] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,098] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,106] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,110] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 17:21:40,116] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,116] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,125] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,128] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2020-02-17 17:21:40,135] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,136] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,147] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,151] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-02-17 17:21:40,160] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,161] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,170] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,174] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-02-17 17:21:40,181] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,181] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,191] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,195] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 17:21:40,201] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,202] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,211] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,215] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 17:21:40,221] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,222] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,231] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,234] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 17:21:40,242] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,242] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,252] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,255] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 17:21:40,263] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,263] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,273] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,277] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 17:21:40,284] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,284] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,294] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,297] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 17:21:40,303] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,303] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,312] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,316] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 17:21:40,321] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,322] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,331] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,335] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 17:21:40,342] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,343] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,353] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,356] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-02-17 17:21:40,362] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,363] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,372] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,376] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 17:21:40,382] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,383] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,393] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,396] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 17:21:40,402] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,402] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,412] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,415] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2020-02-17 17:21:40,422] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,425] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,435] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,438] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-02-17 17:21:40,446] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,447] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,456] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,461] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-02-17 17:21:40,467] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,467] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,477] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,481] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 17:21:40,487] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,487] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,498] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,502] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 17:21:40,512] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,513] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,522] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,528] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-02-17 17:21:40,535] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,536] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,544] INFO [ProducerStateManager partition=__consumer_offsets-44] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-02-17 17:21:40,550] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,554] INFO [ProducerStateManager partition=__consumer_offsets-44] Loading producer state from snapshot file 'C:\tmp\kafka-logs\__consumer_offsets-44\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2020-02-17 17:21:40,555] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 24 ms (kafka.log.Log)
[2020-02-17 17:21:40,564] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,566] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,579] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,583] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2020-02-17 17:21:40,593] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,594] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,603] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,607] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-02-17 17:21:40,615] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,615] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,627] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,632] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-02-17 17:21:40,639] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,640] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,650] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,654] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-02-17 17:21:40,663] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,663] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,672] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,677] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-02-17 17:21:40,684] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,685] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,695] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,699] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-02-17 17:21:40,705] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,706] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,720] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,723] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2020-02-17 17:21:40,731] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,731] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,742] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,746] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-02-17 17:21:40,754] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,754] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,764] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,767] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2020-02-17 17:21:40,773] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2020-02-17 17:21:40,774] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,786] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:21:40,789] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-02-17 17:21:40,794] INFO Logs loading complete in 1285 ms. (kafka.log.LogManager)
[2020-02-17 17:21:40,806] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-02-17 17:21:40,811] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-02-17 17:21:41,096] INFO Awaiting socket connections on s0.0.0.0:9092. (kafka.network.Acceptor)
[2020-02-17 17:21:41,134] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-02-17 17:21:41,137] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-02-17 17:21:41,168] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 17:21:41,170] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 17:21:41,171] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 17:21:41,170] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 17:21:41,187] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-02-17 17:21:41,243] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-02-17 17:21:41,268] INFO Stat of the created znode at /brokers/ids/0 is: 327,327,1581952901259,1581952901259,1,0,0,72059121459003392,222,0,327
 (kafka.zk.KafkaZkClient)
[2020-02-17 17:21:41,270] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(aviramco02.corp.amdocs.com,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 327 (kafka.zk.KafkaZkClient)
[2020-02-17 17:21:41,319] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 17:21:41,323] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 17:21:41,326] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 17:21:41,356] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:21:41,358] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:21:41,364] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:41,379] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:6000,blockEndProducerId:6999) by writing to Zk with path version 7 (kafka.coordinator.transaction.ProducerIdManager)
[2020-02-17 17:21:41,419] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-02-17 17:21:41,423] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-02-17 17:21:41,424] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-02-17 17:21:41,481] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-02-17 17:21:41,521] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-02-17 17:21:41,529] INFO Kafka version: 2.2.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-02-17 17:21:41,530] INFO Kafka commitId: 55783d3133a5a49a (org.apache.kafka.common.utils.AppInfoParser)
[2020-02-17 17:21:41,534] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-02-17 17:21:41,602] INFO Got user-level KeeperException when processing sessionid:0x1000163a1640000 type:multi cxid:0x77 zxid:0x14a txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:21:41,651] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, javainuse-topic-0, __consumer_offsets-48, microservicestopic-0, __consumer_offsets-19, __consumer_offsets-11, sentorderstatus-0, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, setorderstatus-0, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, getorderstatus-0, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-02-17 17:21:41,666] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,671] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,696] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,696] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,707] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,707] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,716] INFO Replica loaded for partition javainuse-topic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,717] INFO [Partition javainuse-topic-0 broker=0] javainuse-topic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,726] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,727] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,736] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,737] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,745] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,746] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,753] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,754] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,762] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,763] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,771] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,772] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,780] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,781] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,788] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,789] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,797] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,798] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,806] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,807] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,815] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,815] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,824] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,825] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,832] INFO Replica loaded for partition setorderstatus-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,833] INFO [Partition setorderstatus-0 broker=0] setorderstatus-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,840] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,842] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,849] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,850] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,858] INFO Replica loaded for partition microservicestopic-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,859] INFO [Partition microservicestopic-0 broker=0] microservicestopic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,866] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,866] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,874] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,874] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,882] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,882] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,890] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,891] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,899] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,899] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,907] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,908] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,916] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,916] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,925] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,925] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,932] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,933] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,940] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,941] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,948] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,948] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,956] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,957] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,965] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,965] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,972] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,972] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,980] INFO Replica loaded for partition sentorderstatus-0 with initial high watermark 3 (kafka.cluster.Replica)
[2020-02-17 17:21:41,981] INFO [Partition sentorderstatus-0 broker=0] sentorderstatus-0 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,985] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,986] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:41,993] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:41,994] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,001] INFO Replica loaded for partition getorderstatus-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:42,001] INFO [Partition getorderstatus-0 broker=0] getorderstatus-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,009] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:42,010] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,016] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:42,017] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,024] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:42,025] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,031] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:42,032] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,039] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:42,039] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,046] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:42,047] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,054] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:42,054] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,062] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:42,064] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,071] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:42,071] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,078] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 1 (kafka.cluster.Replica)
[2020-02-17 17:21:42,079] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,082] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:42,083] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,090] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:42,091] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,098] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:42,099] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,105] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:42,106] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,113] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:42,113] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,120] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:21:42,120] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,128] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 12 (kafka.cluster.Replica)
[2020-02-17 17:21:42,128] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 12. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:21:42,137] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,138] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,138] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,140] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,141] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,144] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,145] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,146] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,149] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,149] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,150] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,151] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,152] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,155] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,166] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,169] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,170] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,171] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,173] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,179] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,180] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,182] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,183] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,184] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,182] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 44 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,195] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,198] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,199] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,199] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,200] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,201] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,202] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,204] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,206] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,206] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,208] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,209] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,210] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,210] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,211] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,212] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,213] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,216] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,217] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,218] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,219] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,219] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,221] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,222] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,223] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,223] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,224] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,227] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,228] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,229] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,230] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,231] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,232] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,232] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,233] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,234] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,256] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-10831 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:21:42,262] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 42 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,263] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,265] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,266] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,266] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,267] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,277] INFO [GroupCoordinator 0]: Loading group metadata for group_id with generation 8 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:21:42,278] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 9 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,280] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,282] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,282] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,283] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,284] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,285] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,285] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,286] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,288] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,292] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,292] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,293] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,294] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,296] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,297] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,298] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,299] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,300] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,301] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,304] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,305] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,306] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,307] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,308] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,309] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,309] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,310] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,312] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,315] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,316] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,317] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:42,317] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:21:52,265] INFO [GroupCoordinator 0]: Member consumer-1-05c8d1d4-5335-4870-95d5-4f289e246b75 in group console-consumer-10831 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:21:52,267] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-10831 in state PreparingRebalance with old generation 1 (__consumer_offsets-44) (reason: removing member consumer-1-05c8d1d4-5335-4870-95d5-4f289e246b75 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:21:52,270] INFO [GroupCoordinator 0]: Group console-consumer-10831 with generation 2 is now empty (__consumer_offsets-44) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:22:14,998] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-55593 in state PreparingRebalance with old generation 0 (__consumer_offsets-38) (reason: Adding new member consumer-1-59c876df-3755-45e4-a91b-286e64219dd4) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:22:15,004] INFO [GroupCoordinator 0]: Stabilized group console-consumer-55593 generation 1 (__consumer_offsets-38) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:22:15,013] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-55593 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:22:56,203] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 8 (__consumer_offsets-13) (reason: Adding new member consumer-1-b16fd143-52e3-40ec-805b-0aa0edd2d3b5) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:22:56,205] INFO [GroupCoordinator 0]: Stabilized group group_id generation 9 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:22:56,218] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 9 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:23:06,269] INFO [GroupCoordinator 0]: Member consumer-1-b16fd143-52e3-40ec-805b-0aa0edd2d3b5 in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:23:06,270] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 9 (__consumer_offsets-13) (reason: removing member consumer-1-b16fd143-52e3-40ec-805b-0aa0edd2d3b5 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:23:06,271] INFO [GroupCoordinator 0]: Group group_id with generation 10 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:24:28,439] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 10 (__consumer_offsets-13) (reason: Adding new member consumer-1-e2ab6e22-866b-4ccb-a3cf-d5f2a2988941) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:24:28,442] INFO [GroupCoordinator 0]: Stabilized group group_id generation 11 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:24:28,455] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 11 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:24:38,503] INFO [GroupCoordinator 0]: Member consumer-1-e2ab6e22-866b-4ccb-a3cf-d5f2a2988941 in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:24:38,504] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 11 (__consumer_offsets-13) (reason: removing member consumer-1-e2ab6e22-866b-4ccb-a3cf-d5f2a2988941 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:24:38,509] INFO [GroupCoordinator 0]: Group group_id with generation 12 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:24:54,934] WARN Session 0x1000163a1640000 for server localhost/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:68)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:366)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1145)
[2020-02-17 17:24:56,463] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-02-17 17:24:57,474] INFO Socket error occurred: localhost/127.0.0.1:2181: Connection refused: no further information (org.apache.zookeeper.ClientCnxn)
[2020-02-17 17:24:58,837] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-02-17 17:26:01,274] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-02-17 17:26:01,276] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-17 17:26:01,276] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-17 17:26:01,277] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-02-17 17:26:01,277] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-02-17 17:26:01,289] INFO Reading configuration from: .\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-02-17 17:26:01,290] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-02-17 17:26:01,297] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,298] INFO Server environment:host.name=aviramco02.corp.amdocs.com (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,298] INFO Server environment:java.version=1.8.0_221 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,298] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,298] INFO Server environment:java.home=C:\Program Files\Java\jdk1.8.0_221\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,299] INFO Server environment:java.class.path=C:\kafka_2.12-2.2.1\libs\activation-1.1.1.jar;C:\kafka_2.12-2.2.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.12-2.2.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.12-2.2.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.12-2.2.1\libs\connect-api-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-basic-auth-extension-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-file-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-json-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-runtime-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-transforms-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\guava-20.0.jar;C:\kafka_2.12-2.2.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-datatype-jdk8-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.12-2.2.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-1.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.12-2.2.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.12-2.2.1\libs\jersey-client-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-common-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-server-2.27.jar;C:\kafka_2.12-2.2.1\libs\jetty-client-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-continuation-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-http-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-io-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-security-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-server-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlet-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlets-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-util-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.12-2.2.1\libs\kafka-clients-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-log4j-appender-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-examples-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-scala_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-test-utils-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-tools-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar.asc;C:\kafka_2.12-2.2.1\libs\log4j-1.2.17.jar;C:\kafka_2.12-2.2.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.12-2.2.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.12-2.2.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.12-2.2.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.12-2.2.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\reflections-0.9.11.jar;C:\kafka_2.12-2.2.1\libs\rocksdbjni-5.15.10.jar;C:\kafka_2.12-2.2.1\libs\scala-library-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\scala-logging_2.12-3.9.0.jar;C:\kafka_2.12-2.2.1\libs\scala-reflect-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.12-2.2.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.12-2.2.1\libs\zkclient-0.11.jar;C:\kafka_2.12-2.2.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.12-2.2.1\libs\zstd-jni-1.3.8-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,302] INFO Server environment:java.library.path=C:\Program Files\Java\jdk1.8.0_221\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;c:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files\Perforce\;C:\Program Files (x86)\Symantec\VIP Access Client\;C:\Program Files\Git\cmd;C:\apache-maven-3.6.1\bin;C:\Program Files\Redis\;C:\Program Files\Java\jdk1.8.0_221\bin;C:\Program Files\nodejs\;C:\apache-maven-3.6.1\bin;C:\Program Files (x86)\Brackets\command;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\TortoiseGit\bin;C:\Users\aviramco\AppData\Roaming\Cloud Foundry;C:\apache-zookeeper-3.5.5-bin\bin;C:\Users\aviramco\AppData\Local\Microsoft\WindowsApps;;C:\Users\aviramco\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\aviramco\AppData\Roaming\npm;. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,303] INFO Server environment:java.io.tmpdir=C:\Users\aviramco\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,306] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,307] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,307] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,308] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,309] INFO Server environment:user.name=aviramco (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,311] INFO Server environment:user.home=C:\Users\aviramco (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,311] INFO Server environment:user.dir=C:\kafka_2.12-2.2.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,319] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,319] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,320] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:01,333] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-02-17 17:26:01,335] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-17 17:26:21,510] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-02-17 17:26:21,959] INFO starting (kafka.server.KafkaServer)
[2020-02-17 17:26:21,960] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-02-17 17:26:21,979] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 17:26:21,985] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:26:21,985] INFO Client environment:host.name=aviramco02.corp.amdocs.com (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:26:21,986] INFO Client environment:java.version=1.8.0_221 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:26:21,986] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:26:21,986] INFO Client environment:java.home=C:\Program Files\Java\jdk1.8.0_221\jre (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:26:21,986] INFO Client environment:java.class.path=C:\kafka_2.12-2.2.1\libs\activation-1.1.1.jar;C:\kafka_2.12-2.2.1\libs\aopalliance-repackaged-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\argparse4j-0.7.0.jar;C:\kafka_2.12-2.2.1\libs\audience-annotations-0.5.0.jar;C:\kafka_2.12-2.2.1\libs\commons-lang3-3.8.1.jar;C:\kafka_2.12-2.2.1\libs\connect-api-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-basic-auth-extension-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-file-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-json-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-runtime-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\connect-transforms-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\guava-20.0.jar;C:\kafka_2.12-2.2.1\libs\hk2-api-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-locator-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\hk2-utils-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\jackson-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-core-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-databind-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-datatype-jdk8-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-base-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-jaxrs-json-provider-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\jackson-module-jaxb-annotations-2.9.8.jar;C:\kafka_2.12-2.2.1\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.12-2.2.1\libs\javax.annotation-api-1.2.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-1.jar;C:\kafka_2.12-2.2.1\libs\javax.inject-2.5.0-b42.jar;C:\kafka_2.12-2.2.1\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.12-2.2.1\libs\javax.ws.rs-api-2.1.jar;C:\kafka_2.12-2.2.1\libs\jaxb-api-2.3.0.jar;C:\kafka_2.12-2.2.1\libs\jersey-client-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-common-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-container-servlet-core-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-hk2-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-media-jaxb-2.27.jar;C:\kafka_2.12-2.2.1\libs\jersey-server-2.27.jar;C:\kafka_2.12-2.2.1\libs\jetty-client-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-continuation-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-http-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-io-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-security-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-server-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlet-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-servlets-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jetty-util-9.4.14.v20181114.jar;C:\kafka_2.12-2.2.1\libs\jopt-simple-5.0.4.jar;C:\kafka_2.12-2.2.1\libs\kafka-clients-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-log4j-appender-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-examples-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-scala_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-streams-test-utils-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka-tools-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-javadoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-scaladoc.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test-sources.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1-test.jar.asc;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar;C:\kafka_2.12-2.2.1\libs\kafka_2.12-2.2.1.jar.asc;C:\kafka_2.12-2.2.1\libs\log4j-1.2.17.jar;C:\kafka_2.12-2.2.1\libs\lz4-java-1.5.0.jar;C:\kafka_2.12-2.2.1\libs\maven-artifact-3.6.0.jar;C:\kafka_2.12-2.2.1\libs\metrics-core-2.2.0.jar;C:\kafka_2.12-2.2.1\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.12-2.2.1\libs\plexus-utils-3.1.0.jar;C:\kafka_2.12-2.2.1\libs\reflections-0.9.11.jar;C:\kafka_2.12-2.2.1\libs\rocksdbjni-5.15.10.jar;C:\kafka_2.12-2.2.1\libs\scala-library-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\scala-logging_2.12-3.9.0.jar;C:\kafka_2.12-2.2.1\libs\scala-reflect-2.12.8.jar;C:\kafka_2.12-2.2.1\libs\slf4j-api-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\slf4j-log4j12-1.7.25.jar;C:\kafka_2.12-2.2.1\libs\snappy-java-1.1.7.2.jar;C:\kafka_2.12-2.2.1\libs\validation-api-1.1.0.Final.jar;C:\kafka_2.12-2.2.1\libs\zkclient-0.11.jar;C:\kafka_2.12-2.2.1\libs\zookeeper-3.4.13.jar;C:\kafka_2.12-2.2.1\libs\zstd-jni-1.3.8-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:26:21,991] INFO Client environment:java.library.path=C:\Program Files\Java\jdk1.8.0_221\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\RSA SecurID Token Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;c:\Program Files (x86)\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\Tools\Binn\;c:\Program Files\Microsoft SQL Server\100\DTS\Binn\;C:\Program Files\Perforce\;C:\Program Files (x86)\Symantec\VIP Access Client\;C:\Program Files\Git\cmd;C:\apache-maven-3.6.1\bin;C:\Program Files\Redis\;C:\Program Files\Java\jdk1.8.0_221\bin;C:\Program Files\nodejs\;C:\apache-maven-3.6.1\bin;C:\Program Files (x86)\Brackets\command;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\TortoiseGit\bin;C:\Users\aviramco\AppData\Roaming\Cloud Foundry;C:\apache-zookeeper-3.5.5-bin\bin;C:\Users\aviramco\AppData\Local\Microsoft\WindowsApps;;C:\Users\aviramco\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\aviramco\AppData\Roaming\npm;. (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:26:21,992] INFO Client environment:java.io.tmpdir=C:\Users\aviramco\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:26:21,995] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:26:21,996] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:26:21,997] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:26:21,998] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:26:21,999] INFO Client environment:user.name=aviramco (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:26:22,000] INFO Client environment:user.home=C:\Users\aviramco (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:26:22,000] INFO Client environment:user.dir=C:\kafka_2.12-2.2.1 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:26:22,003] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@769f71a9 (org.apache.zookeeper.ZooKeeper)
[2020-02-17 17:26:22,019] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 17:26:22,019] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-02-17 17:26:22,022] INFO Accepted socket connection from /127.0.0.1:3361 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-17 17:26:22,022] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-02-17 17:26:22,030] INFO Client attempting to establish new session at /127.0.0.1:3361 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:22,032] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-02-17 17:26:22,045] INFO Established session 0x1000167d2c90000 with negotiated timeout 6000 for client /127.0.0.1:3361 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:22,047] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000167d2c90000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-02-17 17:26:22,052] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-02-17 17:26:22,109] INFO Got user-level KeeperException when processing sessionid:0x1000167d2c90000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:26:22,119] INFO Got user-level KeeperException when processing sessionid:0x1000167d2c90000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:26:22,127] INFO Got user-level KeeperException when processing sessionid:0x1000167d2c90000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:26:22,293] INFO Got user-level KeeperException when processing sessionid:0x1000167d2c90000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:26:22,299] INFO Cluster ID = 58EqiUmaRxeeJyKbuKHAJA (kafka.server.KafkaServer)
[2020-02-17 17:26:22,302] WARN No meta.properties file under dir C:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-02-17 17:26:22,354] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-17 17:26:22,368] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.2-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.2-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-02-17 17:26:22,394] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 17:26:22,394] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 17:26:22,396] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-02-17 17:26:22,419] INFO Log directory C:\tmp\kafka-logs not found, creating it. (kafka.log.LogManager)
[2020-02-17 17:26:22,428] INFO Loading logs. (kafka.log.LogManager)
[2020-02-17 17:26:22,436] INFO Logs loading complete in 7 ms. (kafka.log.LogManager)
[2020-02-17 17:26:22,451] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-02-17 17:26:22,456] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-02-17 17:26:22,701] INFO Awaiting socket connections on s0.0.0.0:9092. (kafka.network.Acceptor)
[2020-02-17 17:26:22,732] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-02-17 17:26:22,734] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-02-17 17:26:22,757] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 17:26:22,759] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 17:26:22,760] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 17:26:22,761] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 17:26:22,771] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-02-17 17:26:22,792] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-02-17 17:26:22,810] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1581953182802,1581953182802,1,0,0,72059139467575296,222,0,24
 (kafka.zk.KafkaZkClient)
[2020-02-17 17:26:22,811] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(aviramco02.corp.amdocs.com,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2020-02-17 17:26:22,815] WARN No meta.properties file under dir C:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-02-17 17:26:22,862] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 17:26:22,865] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 17:26:22,866] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-02-17 17:26:22,872] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-02-17 17:26:22,885] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:26:22,887] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:26:22,894] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:26:22,903] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-02-17 17:26:22,925] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-02-17 17:26:22,927] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-02-17 17:26:22,927] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-02-17 17:26:22,974] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-02-17 17:26:22,989] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-02-17 17:26:22,997] INFO Kafka version: 2.2.1 (org.apache.kafka.common.utils.AppInfoParser)
[2020-02-17 17:26:22,997] INFO Kafka commitId: 55783d3133a5a49a (org.apache.kafka.common.utils.AppInfoParser)
[2020-02-17 17:26:23,000] INFO Got user-level KeeperException when processing sessionid:0x1000167d2c90000 type:multi cxid:0x38 zxid:0x1c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:26:23,003] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-02-17 17:26:49,596] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:3385 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-17 17:26:49,599] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:3385 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:49,604] INFO Established session 0x1000167d2c90001 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:3385 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-17 17:26:49,846] INFO Got user-level KeeperException when processing sessionid:0x1000167d2c90001 type:setData cxid:0x4 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/sentorderstatus Error:KeeperErrorCode = NoNode for /config/topics/sentorderstatus (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:26:49,887] INFO Processed session termination for sessionid: 0x1000167d2c90001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:26:49,891] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:3385 which had sessionid 0x1000167d2c90001 (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-17 17:26:49,940] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(sentorderstatus-0) (kafka.server.ReplicaFetcherManager)
[2020-02-17 17:26:49,994] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:26:50,004] INFO [Log partition=sentorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2020-02-17 17:26:50,006] INFO Created log for partition sentorderstatus-0 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:26:50,010] INFO [Partition sentorderstatus-0 broker=0] No checkpointed highwatermark is found for partition sentorderstatus-0 (kafka.cluster.Partition)
[2020-02-17 17:26:50,012] INFO Replica loaded for partition sentorderstatus-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:26:50,015] INFO [Partition sentorderstatus-0 broker=0] sentorderstatus-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:41,888] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-02-17 17:27:41,891] INFO Got user-level KeeperException when processing sessionid:0x1000167d2c90000 type:setData cxid:0x47 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:27:41,902] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-02-17 17:27:42,052] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-02-17 17:27:42,063] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,067] INFO [Log partition=__consumer_offsets-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-02-17 17:27:42,068] INFO Created log for partition __consumer_offsets-0 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,070] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-02-17 17:27:42,070] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,071] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,082] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,086] INFO [Log partition=__consumer_offsets-29, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 17:27:42,087] INFO Created log for partition __consumer_offsets-29 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,090] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-02-17 17:27:42,090] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,091] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,101] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,103] INFO [Log partition=__consumer_offsets-48, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-02-17 17:27:42,105] INFO Created log for partition __consumer_offsets-48 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,106] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-02-17 17:27:42,106] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,107] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,118] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,122] INFO [Log partition=__consumer_offsets-10, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 17:27:42,123] INFO Created log for partition __consumer_offsets-10 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,125] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-02-17 17:27:42,125] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,126] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,135] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,138] INFO [Log partition=__consumer_offsets-45, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 17:27:42,140] INFO Created log for partition __consumer_offsets-45 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,141] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-02-17 17:27:42,142] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,142] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,152] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,155] INFO [Log partition=__consumer_offsets-26, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 17:27:42,156] INFO Created log for partition __consumer_offsets-26 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,159] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-02-17 17:27:42,159] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,160] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,169] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,173] INFO [Log partition=__consumer_offsets-7, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 17:27:42,175] INFO Created log for partition __consumer_offsets-7 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,176] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-02-17 17:27:42,176] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,177] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,190] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,193] INFO [Log partition=__consumer_offsets-42, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-02-17 17:27:42,194] INFO Created log for partition __consumer_offsets-42 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,195] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-02-17 17:27:42,196] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,197] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,206] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,209] INFO [Log partition=__consumer_offsets-4, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 17:27:42,210] INFO Created log for partition __consumer_offsets-4 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,211] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-02-17 17:27:42,212] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,213] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,225] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,227] INFO [Log partition=__consumer_offsets-23, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 17:27:42,228] INFO Created log for partition __consumer_offsets-23 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,230] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-02-17 17:27:42,230] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,230] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,241] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,244] INFO [Log partition=__consumer_offsets-1, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 17:27:42,245] INFO Created log for partition __consumer_offsets-1 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,246] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,247] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,247] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,259] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,261] INFO [Log partition=__consumer_offsets-20, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 17:27:42,262] INFO Created log for partition __consumer_offsets-20 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,264] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-02-17 17:27:42,264] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,265] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,277] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,280] INFO [Log partition=__consumer_offsets-39, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 17:27:42,281] INFO Created log for partition __consumer_offsets-39 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,282] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-02-17 17:27:42,283] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,283] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,297] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,299] INFO [Log partition=__consumer_offsets-17, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 17:27:42,300] INFO Created log for partition __consumer_offsets-17 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,302] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-02-17 17:27:42,302] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,303] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,313] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,316] INFO [Log partition=__consumer_offsets-36, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 17:27:42,317] INFO Created log for partition __consumer_offsets-36 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,318] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-02-17 17:27:42,318] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,319] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,329] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,332] INFO [Log partition=__consumer_offsets-14, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-02-17 17:27:42,333] INFO Created log for partition __consumer_offsets-14 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,333] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-02-17 17:27:42,334] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,335] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,346] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,348] INFO [Log partition=__consumer_offsets-33, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-02-17 17:27:42,349] INFO Created log for partition __consumer_offsets-33 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,350] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-02-17 17:27:42,352] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,353] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,364] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,366] INFO [Log partition=__consumer_offsets-49, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 17:27:42,367] INFO Created log for partition __consumer_offsets-49 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,368] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-02-17 17:27:42,368] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,369] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,379] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,382] INFO [Log partition=__consumer_offsets-11, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 17:27:42,383] INFO Created log for partition __consumer_offsets-11 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,384] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-02-17 17:27:42,385] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,385] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,398] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,400] INFO [Log partition=__consumer_offsets-30, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 17:27:42,401] INFO Created log for partition __consumer_offsets-30 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,402] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-02-17 17:27:42,402] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,403] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,415] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,417] INFO [Log partition=__consumer_offsets-46, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-02-17 17:27:42,418] INFO Created log for partition __consumer_offsets-46 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,419] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-02-17 17:27:42,420] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,421] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,431] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,433] INFO [Log partition=__consumer_offsets-27, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-02-17 17:27:42,440] INFO Created log for partition __consumer_offsets-27 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,441] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-02-17 17:27:42,442] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,443] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,453] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,457] INFO [Log partition=__consumer_offsets-8, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 17:27:42,458] INFO Created log for partition __consumer_offsets-8 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,460] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-02-17 17:27:42,460] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,461] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,473] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,476] INFO [Log partition=__consumer_offsets-24, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 17:27:42,477] INFO Created log for partition __consumer_offsets-24 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,478] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-02-17 17:27:42,478] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,479] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,493] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,497] INFO [Log partition=__consumer_offsets-43, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2020-02-17 17:27:42,498] INFO Created log for partition __consumer_offsets-43 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,500] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-02-17 17:27:42,500] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,501] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,512] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,515] INFO [Log partition=__consumer_offsets-5, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-02-17 17:27:42,516] INFO Created log for partition __consumer_offsets-5 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,517] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-02-17 17:27:42,518] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,519] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,530] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,534] INFO [Log partition=__consumer_offsets-21, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 17:27:42,535] INFO Created log for partition __consumer_offsets-21 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,537] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-02-17 17:27:42,537] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,539] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,549] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,552] INFO [Log partition=__consumer_offsets-2, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 17:27:42,553] INFO Created log for partition __consumer_offsets-2 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,555] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-02-17 17:27:42,556] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,559] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,569] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,573] INFO [Log partition=__consumer_offsets-40, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 17:27:42,575] INFO Created log for partition __consumer_offsets-40 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,576] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-02-17 17:27:42,576] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,577] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,590] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,594] INFO [Log partition=__consumer_offsets-37, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-17 17:27:42,595] INFO Created log for partition __consumer_offsets-37 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,597] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-02-17 17:27:42,597] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,598] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,613] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,616] INFO [Log partition=__consumer_offsets-18, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-02-17 17:27:42,617] INFO Created log for partition __consumer_offsets-18 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,618] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-02-17 17:27:42,618] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,620] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,633] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,637] INFO [Log partition=__consumer_offsets-34, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-17 17:27:42,638] INFO Created log for partition __consumer_offsets-34 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,642] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-02-17 17:27:42,643] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,645] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,654] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,658] INFO [Log partition=__consumer_offsets-15, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 17:27:42,659] INFO Created log for partition __consumer_offsets-15 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,661] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-02-17 17:27:42,661] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,662] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,674] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,678] INFO [Log partition=__consumer_offsets-12, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-17 17:27:42,679] INFO Created log for partition __consumer_offsets-12 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,681] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-02-17 17:27:42,681] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,682] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,695] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,698] INFO [Log partition=__consumer_offsets-31, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 17:27:42,699] INFO Created log for partition __consumer_offsets-31 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,701] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-02-17 17:27:42,703] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,704] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,716] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,718] INFO [Log partition=__consumer_offsets-9, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2020-02-17 17:27:42,719] INFO Created log for partition __consumer_offsets-9 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,720] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-02-17 17:27:42,723] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,727] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,737] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,741] INFO [Log partition=__consumer_offsets-47, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 17:27:42,742] INFO Created log for partition __consumer_offsets-47 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,743] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-02-17 17:27:42,744] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,745] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,757] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,761] INFO [Log partition=__consumer_offsets-19, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-17 17:27:42,762] INFO Created log for partition __consumer_offsets-19 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,763] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-02-17 17:27:42,763] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,764] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,776] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,780] INFO [Log partition=__consumer_offsets-28, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-17 17:27:42,781] INFO Created log for partition __consumer_offsets-28 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,782] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-02-17 17:27:42,783] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,784] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,795] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,799] INFO [Log partition=__consumer_offsets-38, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2020-02-17 17:27:42,801] INFO Created log for partition __consumer_offsets-38 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,802] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-02-17 17:27:42,803] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,804] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,817] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,820] INFO [Log partition=__consumer_offsets-35, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 17:27:42,821] INFO Created log for partition __consumer_offsets-35 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,823] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-02-17 17:27:42,825] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,826] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,838] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,843] INFO [Log partition=__consumer_offsets-44, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-17 17:27:42,845] INFO Created log for partition __consumer_offsets-44 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,846] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-02-17 17:27:42,847] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,848] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,860] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,864] INFO [Log partition=__consumer_offsets-6, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-02-17 17:27:42,865] INFO Created log for partition __consumer_offsets-6 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,867] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-02-17 17:27:42,867] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,868] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,881] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,885] INFO [Log partition=__consumer_offsets-25, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-02-17 17:27:42,886] INFO Created log for partition __consumer_offsets-25 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,887] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-02-17 17:27:42,887] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,889] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,901] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,906] INFO [Log partition=__consumer_offsets-16, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-17 17:27:42,908] INFO Created log for partition __consumer_offsets-16 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,910] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-02-17 17:27:42,911] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,912] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,924] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,927] INFO [Log partition=__consumer_offsets-22, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-02-17 17:27:42,928] INFO Created log for partition __consumer_offsets-22 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,929] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-02-17 17:27:42,930] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,930] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,943] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,946] INFO [Log partition=__consumer_offsets-41, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-02-17 17:27:42,947] INFO Created log for partition __consumer_offsets-41 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,948] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-02-17 17:27:42,949] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,949] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,961] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,965] INFO [Log partition=__consumer_offsets-32, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2020-02-17 17:27:42,966] INFO Created log for partition __consumer_offsets-32 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,967] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-02-17 17:27:42,967] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,968] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:42,983] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:42,986] INFO [Log partition=__consumer_offsets-3, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 17:27:42,987] INFO Created log for partition __consumer_offsets-3 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:42,989] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-02-17 17:27:42,989] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:42,991] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:43,001] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:27:43,004] INFO [Log partition=__consumer_offsets-13, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2020-02-17 17:27:43,005] INFO Created log for partition __consumer_offsets-13 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:27:43,009] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-02-17 17:27:43,010] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:27:43,010] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:27:43,018] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,019] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,020] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,020] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,021] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,022] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,023] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,025] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,025] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,026] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,026] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,028] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,029] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,030] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,030] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,031] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,031] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,032] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,032] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,033] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,033] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,034] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,035] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,036] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,036] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,037] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,041] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,042] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,043] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,043] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,044] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,045] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,045] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,046] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,047] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,048] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,048] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,049] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,049] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,053] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,053] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,054] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,055] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,057] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,056] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,057] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,058] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,059] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,060] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,060] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,063] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,064] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,066] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,066] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,067] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,067] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,068] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,069] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,069] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,070] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,071] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,071] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,076] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,076] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,077] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,077] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,078] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,079] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,079] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,080] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,081] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,081] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,082] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,083] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,084] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,084] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,087] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,088] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,089] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,090] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,091] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,091] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,092] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,093] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,094] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,094] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,095] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,095] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,096] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,100] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,101] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,102] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,102] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,103] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,105] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,107] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,111] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,112] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,113] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,114] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:27:43,160] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-76195 in state PreparingRebalance with old generation 0 (__consumer_offsets-29) (reason: Adding new member consumer-1-45283ea7-c20e-4b79-b705-bdeaf931d0ca) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:27:43,169] INFO [GroupCoordinator 0]: Stabilized group console-consumer-76195 generation 1 (__consumer_offsets-29) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:27:43,179] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-76195 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:28:18,617] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 0 (__consumer_offsets-13) (reason: Adding new member consumer-1-117c9fdd-5720-46b1-924d-31963ed74b56) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:28:18,620] INFO [GroupCoordinator 0]: Stabilized group group_id generation 1 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:28:18,633] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:36:04,826] INFO [GroupCoordinator 0]: Member consumer-1-117c9fdd-5720-46b1-924d-31963ed74b56 in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:36:04,828] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 1 (__consumer_offsets-13) (reason: removing member consumer-1-117c9fdd-5720-46b1-924d-31963ed74b56 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:36:04,831] INFO [GroupCoordinator 0]: Group group_id with generation 2 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:36:22,901] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:36:36,066] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 2 (__consumer_offsets-13) (reason: Adding new member consumer-1-b8755a0f-169d-4519-a624-4c350d39055b) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:36:36,069] INFO [GroupCoordinator 0]: Stabilized group group_id generation 3 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:36:36,081] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 3 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:38:37,024] INFO Creating topic getorderstatus with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-02-17 17:38:37,026] INFO Got user-level KeeperException when processing sessionid:0x1000167d2c90000 type:setData cxid:0x107 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/config/topics/getorderstatus Error:KeeperErrorCode = NoNode for /config/topics/getorderstatus (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-17 17:38:37,039] INFO [KafkaApi-0] Auto creation of topic getorderstatus with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-02-17 17:38:37,061] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(getorderstatus-0) (kafka.server.ReplicaFetcherManager)
[2020-02-17 17:38:37,071] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-17 17:38:37,075] INFO [Log partition=getorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-17 17:38:37,078] INFO Created log for partition getorderstatus-0 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-17 17:38:37,083] INFO [Partition getorderstatus-0 broker=0] No checkpointed highwatermark is found for partition getorderstatus-0 (kafka.cluster.Partition)
[2020-02-17 17:38:37,085] INFO Replica loaded for partition getorderstatus-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-17 17:38:37,086] INFO [Partition getorderstatus-0 broker=0] getorderstatus-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-17 17:39:35,443] INFO [GroupCoordinator 0]: Member consumer-1-b8755a0f-169d-4519-a624-4c350d39055b in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:39:35,444] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 3 (__consumer_offsets-13) (reason: removing member consumer-1-b8755a0f-169d-4519-a624-4c350d39055b on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:39:35,446] INFO [GroupCoordinator 0]: Group group_id with generation 4 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:40:14,328] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 4 (__consumer_offsets-13) (reason: Adding new member consumer-2-64b49f27-6470-4e19-86ac-58711f687f2e) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:40:14,334] INFO [GroupCoordinator 0]: Stabilized group group_id generation 5 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:40:14,349] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 5 (kafka.coordinator.group.GroupCoordinator)
[2020-02-17 17:46:22,884] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 17:56:22,881] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-17 18:06:22,881] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:30:47,609] WARN Attempting to send response via channel for which there is no open connection, connection id 172.22.165.204:9092-172.22.165.204:2788-9 (kafka.network.Processor)
[2020-02-18 08:30:49,389] WARN Client session timed out, have not heard from server in 51484432ms for sessionid 0x1000167d2c90000 (org.apache.zookeeper.ClientCnxn)
[2020-02-18 08:30:47,739] INFO [GroupCoordinator 0]: Member consumer-2-64b49f27-6470-4e19-86ac-58711f687f2e in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 08:30:50,739] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 5 (__consumer_offsets-13) (reason: removing member consumer-2-64b49f27-6470-4e19-86ac-58711f687f2e on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 08:30:50,446] INFO Expiring session 0x1000167d2c90000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-18 08:30:50,654] INFO Client session timed out, have not heard from server in 51484432ms for sessionid 0x1000167d2c90000, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2020-02-18 08:30:50,866] INFO Processed session termination for sessionid: 0x1000167d2c90000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-18 08:30:50,819] INFO [GroupCoordinator 0]: Group group_id with generation 6 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 08:30:50,893] WARN Unable to read additional data from client sessionid 0x1000167d2c90000, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-18 08:30:50,930] INFO Closed socket connection for client /127.0.0.1:3361 which had sessionid 0x1000167d2c90000 (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-18 08:30:50,983] INFO Closed socket connection for client /127.0.0.1:3361 which had sessionid 0x1000167d2c90000 (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-18 08:30:50,961] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 6 (__consumer_offsets-13) (reason: Adding new member consumer-2-af8de240-c03e-4b58-b0e0-8fc52bc7f112) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 08:30:51,040] INFO [GroupCoordinator 0]: Stabilized group group_id generation 7 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 08:30:51,116] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 7 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 08:30:52,144] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-02-18 08:30:52,242] INFO Accepted socket connection from /127.0.0.1:2810 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-18 08:30:52,242] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-02-18 08:30:52,363] INFO Client attempting to renew session 0x1000167d2c90000 at /127.0.0.1:2810 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-18 08:30:52,431] INFO Invalid session 0x1000167d2c90000 for client /127.0.0.1:2810, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-18 08:30:52,458] INFO Closed socket connection for client /127.0.0.1:2810 which had sessionid 0x1000167d2c90000 (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-18 08:30:52,431] WARN Unable to reconnect to ZooKeeper service, session 0x1000167d2c90000 has expired (org.apache.zookeeper.ClientCnxn)
[2020-02-18 08:30:52,433] INFO EventThread shut down for session: 0x1000167d2c90000 (org.apache.zookeeper.ClientCnxn)
[2020-02-18 08:30:52,465] INFO Unable to reconnect to ZooKeeper service, session 0x1000167d2c90000 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2020-02-18 08:30:52,487] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2020-02-18 08:30:52,521] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-02-18 08:30:52,702] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@769f71a9 (org.apache.zookeeper.ZooKeeper)
[2020-02-18 08:30:52,774] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-02-18 08:30:52,797] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-02-18 08:30:52,798] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-02-18 08:30:52,798] INFO Accepted socket connection from /127.0.0.1:2813 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-18 08:30:52,812] INFO Client attempting to establish new session at /127.0.0.1:2813 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-18 08:30:52,817] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000167d2c90002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-02-18 08:30:52,817] INFO Established session 0x1000167d2c90002 with negotiated timeout 6000 for client /127.0.0.1:2813 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-18 08:30:53,394] INFO Stat of the created znode at /brokers/ids/0 is: 149,149,1582007453390,1582007453390,1,0,0,72059139467575298,222,0,149
 (kafka.zk.KafkaZkClient)
[2020-02-18 08:30:53,394] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(aviramco02.corp.amdocs.com,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 149 (kafka.zk.KafkaZkClient)
[2020-02-18 08:30:53,654] INFO Got user-level KeeperException when processing sessionid:0x1000167d2c90002 type:multi cxid:0x4b zxid:0x97 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-18 08:34:25,308] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,309] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,310] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,311] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,312] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,313] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,314] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,314] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,315] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,316] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,316] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,317] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,318] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,318] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,319] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,319] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,320] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,320] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,321] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,321] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,322] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,322] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,323] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,323] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,323] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,324] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,327] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,327] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,328] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,328] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,329] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,329] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,330] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,330] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,331] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,331] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,331] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,332] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,332] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,333] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,333] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,334] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,334] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,335] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,335] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,336] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,336] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,337] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,337] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,338] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,338] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,339] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,340] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,343] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,344] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,345] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,346] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,346] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,347] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,347] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,348] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,348] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,349] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,349] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,350] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,350] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,351] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,352] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,352] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,352] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,353] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,353] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,354] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,354] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,355] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,357] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,358] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,358] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,359] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,360] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,361] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,361] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,362] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,362] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,363] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:34:25,363] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:36:22,865] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:46:22,864] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:56:22,864] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 08:59:53,721] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:4023 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-18 08:59:53,729] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:4023 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-18 08:59:53,731] INFO Established session 0x1000167d2c90003 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:4023 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-18 08:59:54,016] INFO Got user-level KeeperException when processing sessionid:0x1000167d2c90003 type:setData cxid:0x4 zxid:0x99 txntype:-1 reqpath:n/a Error Path:/config/topics/updateorderstatus Error:KeeperErrorCode = NoNode for /config/topics/updateorderstatus (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-18 08:59:54,070] INFO Processed session termination for sessionid: 0x1000167d2c90003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-18 08:59:54,073] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:4023 which had sessionid 0x1000167d2c90003 (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-18 08:59:54,083] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(updateorderstatus-0) (kafka.server.ReplicaFetcherManager)
[2020-02-18 08:59:54,093] INFO [Log partition=updateorderstatus-0, dir=C:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-02-18 08:59:54,096] INFO [Log partition=updateorderstatus-0, dir=C:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2020-02-18 08:59:54,097] INFO Created log for partition updateorderstatus-0 in C:\tmp\kafka-logs with properties {compression.type -> producer, message.format.version -> 2.2-IV1, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2020-02-18 08:59:54,099] INFO [Partition updateorderstatus-0 broker=0] No checkpointed highwatermark is found for partition updateorderstatus-0 (kafka.cluster.Partition)
[2020-02-18 08:59:54,099] INFO Replica loaded for partition updateorderstatus-0 with initial high watermark 0 (kafka.cluster.Replica)
[2020-02-18 08:59:54,099] INFO [Partition updateorderstatus-0 broker=0] updateorderstatus-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-02-18 09:06:22,864] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 09:07:51,772] INFO [GroupCoordinator 0]: Member consumer-2-af8de240-c03e-4b58-b0e0-8fc52bc7f112 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:07:51,774] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 7 (__consumer_offsets-13) (reason: removing member consumer-2-af8de240-c03e-4b58-b0e0-8fc52bc7f112 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:07:51,776] INFO [GroupCoordinator 0]: Group group_id with generation 8 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:08:03,593] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 8 (__consumer_offsets-13) (reason: Adding new member consumer-3-ed1fa6cb-7477-442f-b35c-399c4e62d248) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:08:03,596] INFO [GroupCoordinator 0]: Stabilized group group_id generation 9 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:08:03,599] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 9 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:08:17,264] INFO [GroupCoordinator 0]: Member consumer-3-ed1fa6cb-7477-442f-b35c-399c4e62d248 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:08:17,265] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 9 (__consumer_offsets-13) (reason: removing member consumer-3-ed1fa6cb-7477-442f-b35c-399c4e62d248 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:08:17,267] INFO [GroupCoordinator 0]: Group group_id with generation 10 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:16:22,868] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 09:23:25,748] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 10 (__consumer_offsets-13) (reason: Adding new member consumer-1-df829313-4db1-46ee-acaa-9a11309532b0) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:23:25,755] INFO [GroupCoordinator 0]: Stabilized group group_id generation 11 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:23:25,770] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 11 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:26:22,864] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 09:28:22,460] INFO [GroupCoordinator 0]: Member consumer-1-df829313-4db1-46ee-acaa-9a11309532b0 in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:28:22,461] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 11 (__consumer_offsets-13) (reason: removing member consumer-1-df829313-4db1-46ee-acaa-9a11309532b0 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:28:22,463] INFO [GroupCoordinator 0]: Group group_id with generation 12 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:28:46,943] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 12 (__consumer_offsets-13) (reason: Adding new member consumer-1-ee6e616f-2e80-43f9-bd1e-a22d2a35ff0b) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:28:46,946] INFO [GroupCoordinator 0]: Stabilized group group_id generation 13 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:28:46,957] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 13 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:30:46,002] INFO [GroupCoordinator 0]: Member consumer-1-ee6e616f-2e80-43f9-bd1e-a22d2a35ff0b in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:30:46,002] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 13 (__consumer_offsets-13) (reason: removing member consumer-1-ee6e616f-2e80-43f9-bd1e-a22d2a35ff0b on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:30:46,004] INFO [GroupCoordinator 0]: Group group_id with generation 14 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:31:25,879] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 14 (__consumer_offsets-13) (reason: Adding new member consumer-1-fde07559-f61f-4051-87f7-cf76b68a60b9) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:31:25,881] INFO [GroupCoordinator 0]: Stabilized group group_id generation 15 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:31:25,893] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 15 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:33:59,012] INFO [GroupCoordinator 0]: Member consumer-1-fde07559-f61f-4051-87f7-cf76b68a60b9 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:33:59,014] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 15 (__consumer_offsets-13) (reason: removing member consumer-1-fde07559-f61f-4051-87f7-cf76b68a60b9 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:33:59,018] INFO [GroupCoordinator 0]: Group group_id with generation 16 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:34:11,908] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 16 (__consumer_offsets-13) (reason: Adding new member consumer-2-8185cf8a-5e98-4d47-aa49-26f721abbbf8) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:34:11,911] INFO [GroupCoordinator 0]: Stabilized group group_id generation 17 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:34:11,914] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 17 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:36:22,863] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 09:37:56,495] INFO [GroupCoordinator 0]: Member consumer-2-8185cf8a-5e98-4d47-aa49-26f721abbbf8 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:37:56,495] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 17 (__consumer_offsets-13) (reason: removing member consumer-2-8185cf8a-5e98-4d47-aa49-26f721abbbf8 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:37:56,497] INFO [GroupCoordinator 0]: Group group_id with generation 18 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:38:08,253] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 18 (__consumer_offsets-13) (reason: Adding new member consumer-3-6256ed83-c915-4131-81ed-aee18aa1a7a0) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:38:08,258] INFO [GroupCoordinator 0]: Stabilized group group_id generation 19 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:38:08,263] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 19 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:42:09,539] INFO [GroupCoordinator 0]: Member consumer-3-6256ed83-c915-4131-81ed-aee18aa1a7a0 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:42:09,541] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 19 (__consumer_offsets-13) (reason: removing member consumer-3-6256ed83-c915-4131-81ed-aee18aa1a7a0 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:42:09,543] INFO [GroupCoordinator 0]: Group group_id with generation 20 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:42:21,262] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 20 (__consumer_offsets-13) (reason: Adding new member consumer-4-dba2a434-c53d-44ef-b542-b1e780e56f08) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:42:21,264] INFO [GroupCoordinator 0]: Stabilized group group_id generation 21 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:42:21,296] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 21 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:43:03,363] INFO [GroupCoordinator 0]: Member consumer-4-dba2a434-c53d-44ef-b542-b1e780e56f08 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:43:03,364] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 21 (__consumer_offsets-13) (reason: removing member consumer-4-dba2a434-c53d-44ef-b542-b1e780e56f08 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:43:03,366] INFO [GroupCoordinator 0]: Group group_id with generation 22 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:43:15,147] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 22 (__consumer_offsets-13) (reason: Adding new member consumer-5-4af2de36-144f-4e8a-b95b-1d7551c6c98e) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:43:15,151] INFO [GroupCoordinator 0]: Stabilized group group_id generation 23 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:43:15,154] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 23 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:43:34,850] INFO [GroupCoordinator 0]: Member consumer-5-4af2de36-144f-4e8a-b95b-1d7551c6c98e in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:43:34,854] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 23 (__consumer_offsets-13) (reason: removing member consumer-5-4af2de36-144f-4e8a-b95b-1d7551c6c98e on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:43:34,859] INFO [GroupCoordinator 0]: Group group_id with generation 24 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:43:46,444] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 24 (__consumer_offsets-13) (reason: Adding new member consumer-6-87f0042a-c3bf-4399-aa04-88a0b5e171a9) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:43:46,446] INFO [GroupCoordinator 0]: Stabilized group group_id generation 25 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:43:46,449] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 25 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:44:01,837] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-87811 in state PreparingRebalance with old generation 0 (__consumer_offsets-16) (reason: Adding new member consumer-1-aa6a9281-183a-4dfb-b451-434920cd1df5) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:44:01,839] INFO [GroupCoordinator 0]: Stabilized group console-consumer-87811 generation 1 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:44:01,844] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-87811 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:46:22,864] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 09:49:03,420] INFO [GroupCoordinator 0]: Member consumer-6-87f0042a-c3bf-4399-aa04-88a0b5e171a9 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:49:03,421] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 25 (__consumer_offsets-13) (reason: removing member consumer-6-87f0042a-c3bf-4399-aa04-88a0b5e171a9 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:49:03,424] INFO [GroupCoordinator 0]: Group group_id with generation 26 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:49:15,103] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 26 (__consumer_offsets-13) (reason: Adding new member consumer-7-ee2770c6-2253-4df6-b16e-878c0f5ba927) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:49:15,106] INFO [GroupCoordinator 0]: Stabilized group group_id generation 27 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:49:15,111] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 27 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:50:15,239] INFO [GroupCoordinator 0]: Member consumer-7-ee2770c6-2253-4df6-b16e-878c0f5ba927 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:50:15,241] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 27 (__consumer_offsets-13) (reason: removing member consumer-7-ee2770c6-2253-4df6-b16e-878c0f5ba927 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:50:15,249] INFO [GroupCoordinator 0]: Group group_id with generation 28 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:50:26,250] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 28 (__consumer_offsets-13) (reason: Adding new member consumer-8-ea2ece30-cb3c-463d-8213-f6e1e8f998b8) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:50:26,252] INFO [GroupCoordinator 0]: Stabilized group group_id generation 29 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:50:26,257] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 29 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:53:27,454] INFO [GroupCoordinator 0]: Member consumer-8-ea2ece30-cb3c-463d-8213-f6e1e8f998b8 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:53:27,454] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 29 (__consumer_offsets-13) (reason: removing member consumer-8-ea2ece30-cb3c-463d-8213-f6e1e8f998b8 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:53:27,457] INFO [GroupCoordinator 0]: Group group_id with generation 30 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:53:39,457] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 30 (__consumer_offsets-13) (reason: Adding new member consumer-9-f68c6703-4a5e-41f9-9eb7-f77f1e9c5a71) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:53:39,459] INFO [GroupCoordinator 0]: Stabilized group group_id generation 31 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:53:39,462] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 31 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:56:16,494] INFO [GroupCoordinator 0]: Member consumer-9-f68c6703-4a5e-41f9-9eb7-f77f1e9c5a71 in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:56:16,495] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 31 (__consumer_offsets-13) (reason: removing member consumer-9-f68c6703-4a5e-41f9-9eb7-f77f1e9c5a71 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:56:16,498] INFO [GroupCoordinator 0]: Group group_id with generation 32 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 09:56:22,864] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 10:03:44,770] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 32 (__consumer_offsets-13) (reason: Adding new member consumer-1-d4e5869a-abd9-4428-b316-0994684d18b2) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:03:44,783] INFO [GroupCoordinator 0]: Stabilized group group_id generation 33 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:03:44,869] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 33 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:03:44,982] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 33 (__consumer_offsets-13) (reason: Adding new member consumer-1-9bf4635b-c949-4f1d-aa06-f428329a3b07) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:03:47,946] INFO [GroupCoordinator 0]: Stabilized group group_id generation 34 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:03:48,200] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 34 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:05:18,291] INFO [GroupCoordinator 0]: Member consumer-1-9bf4635b-c949-4f1d-aa06-f428329a3b07 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:05:18,293] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 34 (__consumer_offsets-13) (reason: removing member consumer-1-9bf4635b-c949-4f1d-aa06-f428329a3b07 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:05:18,313] INFO [GroupCoordinator 0]: Stabilized group group_id generation 35 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:05:18,316] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 35 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:05:32,388] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 35 (__consumer_offsets-13) (reason: Adding new member consumer-2-0e80808a-7af1-42e4-b7bd-deb521a52a54) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:05:33,326] INFO [GroupCoordinator 0]: Stabilized group group_id generation 36 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:05:33,633] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 36 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:06:22,864] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 10:08:55,754] INFO [GroupCoordinator 0]: Member consumer-1-d4e5869a-abd9-4428-b316-0994684d18b2 in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:08:55,759] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 36 (__consumer_offsets-13) (reason: removing member consumer-1-d4e5869a-abd9-4428-b316-0994684d18b2 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:08:57,681] INFO [GroupCoordinator 0]: Stabilized group group_id generation 37 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:08:57,685] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 37 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:09:22,874] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 37 (__consumer_offsets-13) (reason: Adding new member consumer-1-14fb1947-efa2-443f-a418-37443a544f7a) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:09:24,697] INFO [GroupCoordinator 0]: Stabilized group group_id generation 38 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:09:25,119] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 38 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:12:38,041] INFO [GroupCoordinator 0]: Member consumer-2-0e80808a-7af1-42e4-b7bd-deb521a52a54 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:12:38,042] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 38 (__consumer_offsets-13) (reason: removing member consumer-2-0e80808a-7af1-42e4-b7bd-deb521a52a54 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:12:40,411] INFO [GroupCoordinator 0]: Stabilized group group_id generation 39 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:12:40,414] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 39 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:12:50,437] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 39 (__consumer_offsets-13) (reason: Adding new member consumer-3-1c712231-91f1-4e7f-af86-e0f9d7b42626) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:12:52,421] INFO [GroupCoordinator 0]: Stabilized group group_id generation 40 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:12:52,621] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 40 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:13:04,086] INFO [GroupCoordinator 0]: Member consumer-3-1c712231-91f1-4e7f-af86-e0f9d7b42626 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:13:04,087] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 40 (__consumer_offsets-13) (reason: removing member consumer-3-1c712231-91f1-4e7f-af86-e0f9d7b42626 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:13:04,627] INFO [GroupCoordinator 0]: Stabilized group group_id generation 41 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:13:04,629] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 41 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:13:15,183] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 41 (__consumer_offsets-13) (reason: Adding new member consumer-4-2e567787-f872-4a54-b9e7-4251d4935480) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:13:16,637] INFO [GroupCoordinator 0]: Stabilized group group_id generation 42 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:13:16,753] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 42 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:16:22,864] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 10:26:22,863] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 10:36:22,993] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 10:42:23,383] INFO [GroupCoordinator 0]: Member consumer-4-2e567787-f872-4a54-b9e7-4251d4935480 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:42:23,386] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 42 (__consumer_offsets-13) (reason: removing member consumer-4-2e567787-f872-4a54-b9e7-4251d4935480 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:42:26,132] INFO [GroupCoordinator 0]: Stabilized group group_id generation 43 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:42:26,134] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 43 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:42:35,871] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 43 (__consumer_offsets-13) (reason: Adding new member consumer-5-4952cabc-5239-442c-847d-f55426f0ef87) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:42:38,141] INFO [GroupCoordinator 0]: Stabilized group group_id generation 44 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:42:38,333] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 44 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 10:46:22,991] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 10:56:22,994] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 11:06:22,995] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 11:16:22,994] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 11:26:22,994] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 11:36:22,994] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 11:46:22,994] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 11:56:22,993] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 12:06:22,993] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 12:16:22,994] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 12:26:22,994] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 12:36:22,993] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 12:46:22,993] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 12:56:22,993] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 13:06:22,980] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 13:16:22,967] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 13:26:22,963] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 13:36:22,970] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 13:46:22,969] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 13:55:52,623] INFO [GroupCoordinator 0]: Member consumer-5-4952cabc-5239-442c-847d-f55426f0ef87 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:55:52,626] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 44 (__consumer_offsets-13) (reason: removing member consumer-5-4952cabc-5239-442c-847d-f55426f0ef87 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:55:53,455] INFO [GroupCoordinator 0]: Stabilized group group_id generation 45 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:55:53,458] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 45 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:56:06,636] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 45 (__consumer_offsets-13) (reason: Adding new member consumer-6-2072e516-0c9e-431c-a15d-497ab310641b) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:56:08,466] INFO [GroupCoordinator 0]: Stabilized group group_id generation 46 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:56:08,502] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 46 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:56:22,960] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 13:56:30,308] INFO [GroupCoordinator 0]: Member consumer-6-2072e516-0c9e-431c-a15d-497ab310641b in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:56:30,309] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 46 (__consumer_offsets-13) (reason: removing member consumer-6-2072e516-0c9e-431c-a15d-497ab310641b on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:56:32,508] INFO [GroupCoordinator 0]: Stabilized group group_id generation 47 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:56:32,510] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 47 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:56:42,235] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 47 (__consumer_offsets-13) (reason: Adding new member consumer-7-a09eb272-c742-4289-b9c2-0bb5cf348124) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:56:44,518] INFO [GroupCoordinator 0]: Stabilized group group_id generation 48 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:56:44,633] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 48 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:56:59,163] INFO [GroupCoordinator 0]: Member consumer-7-a09eb272-c742-4289-b9c2-0bb5cf348124 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:56:59,166] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 48 (__consumer_offsets-13) (reason: removing member consumer-7-a09eb272-c742-4289-b9c2-0bb5cf348124 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:56:59,641] INFO [GroupCoordinator 0]: Stabilized group group_id generation 49 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:56:59,643] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 49 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:57:14,435] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 49 (__consumer_offsets-13) (reason: Adding new member consumer-8-0795d29b-460b-4564-8b16-95b2013b00a2) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:57:14,653] INFO [GroupCoordinator 0]: Stabilized group group_id generation 50 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:57:14,749] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 50 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:57:16,325] INFO [GroupCoordinator 0]: Member consumer-8-0795d29b-460b-4564-8b16-95b2013b00a2 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:57:16,326] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 50 (__consumer_offsets-13) (reason: removing member consumer-8-0795d29b-460b-4564-8b16-95b2013b00a2 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:57:17,753] INFO [GroupCoordinator 0]: Stabilized group group_id generation 51 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:57:17,755] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 51 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:57:27,308] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 51 (__consumer_offsets-13) (reason: Adding new member consumer-9-c8dd72fa-fb5a-4470-8a92-26afb923bdab) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:57:29,760] INFO [GroupCoordinator 0]: Stabilized group group_id generation 52 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:57:29,804] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 52 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:58:26,278] INFO [GroupCoordinator 0]: Member consumer-9-c8dd72fa-fb5a-4470-8a92-26afb923bdab in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:58:26,279] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 52 (__consumer_offsets-13) (reason: removing member consumer-9-c8dd72fa-fb5a-4470-8a92-26afb923bdab on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:58:26,821] INFO [GroupCoordinator 0]: Stabilized group group_id generation 53 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:58:26,822] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 53 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:58:37,365] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 53 (__consumer_offsets-13) (reason: Adding new member consumer-10-433ee6ac-679b-46e8-bc89-7f00f323d59c) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:58:38,830] INFO [GroupCoordinator 0]: Stabilized group group_id generation 54 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:58:39,041] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 54 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:58:58,574] INFO [GroupCoordinator 0]: Member consumer-10-433ee6ac-679b-46e8-bc89-7f00f323d59c in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:58:58,575] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 54 (__consumer_offsets-13) (reason: removing member consumer-10-433ee6ac-679b-46e8-bc89-7f00f323d59c on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:59:00,050] INFO [GroupCoordinator 0]: Stabilized group group_id generation 55 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 13:59:00,052] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 55 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:03:39,120] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 55 (__consumer_offsets-13) (reason: Updating metadata for member consumer-1-14fb1947-efa2-443f-a418-37443a544f7a) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:03:39,124] INFO [GroupCoordinator 0]: Stabilized group group_id generation 56 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:03:39,126] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 56 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:05:43,288] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 56 (__consumer_offsets-13) (reason: Adding new member consumer-1-132c4ffc-845b-4623-99de-c5194e4fc000) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:05:45,151] INFO [GroupCoordinator 0]: Stabilized group group_id generation 57 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:05:45,645] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 57 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:06:22,960] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 14:16:22,959] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 14:26:22,959] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 14:32:38,809] INFO [GroupCoordinator 0]: Member consumer-1-132c4ffc-845b-4623-99de-c5194e4fc000 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:32:38,812] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 57 (__consumer_offsets-13) (reason: removing member consumer-1-132c4ffc-845b-4623-99de-c5194e4fc000 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:32:40,782] INFO [GroupCoordinator 0]: Stabilized group group_id generation 58 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:32:40,783] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 58 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:33:22,264] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 58 (__consumer_offsets-13) (reason: Adding new member consumer-1-b2e3191f-4b02-48cc-9bca-4f722aff601a) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:33:22,794] INFO [GroupCoordinator 0]: Stabilized group group_id generation 59 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:33:23,084] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 59 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:35:01,708] INFO [GroupCoordinator 0]: Member consumer-1-b2e3191f-4b02-48cc-9bca-4f722aff601a in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:35:01,709] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 59 (__consumer_offsets-13) (reason: removing member consumer-1-b2e3191f-4b02-48cc-9bca-4f722aff601a on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:35:02,105] INFO [GroupCoordinator 0]: Stabilized group group_id generation 60 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:35:02,107] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 60 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:35:16,608] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 60 (__consumer_offsets-13) (reason: Adding new member consumer-2-8566d869-b91c-434e-b14c-3c26d921c2d8) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:35:17,115] INFO [GroupCoordinator 0]: Stabilized group group_id generation 61 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:35:17,528] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 61 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 14:36:22,960] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 14:46:22,959] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 14:56:22,961] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 15:03:37,247] INFO [GroupCoordinator 0]: Member consumer-2-8566d869-b91c-434e-b14c-3c26d921c2d8 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:03:37,258] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 61 (__consumer_offsets-13) (reason: removing member consumer-2-8566d869-b91c-434e-b14c-3c26d921c2d8 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:03:39,832] INFO [GroupCoordinator 0]: Stabilized group group_id generation 62 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:03:39,836] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 62 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:03:53,256] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 62 (__consumer_offsets-13) (reason: Adding new member consumer-3-a693a698-fe7a-4786-8899-bd07c2be3ed0) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:03:54,846] INFO [GroupCoordinator 0]: Stabilized group group_id generation 63 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:03:55,170] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 63 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:06:22,964] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 15:08:24,119] INFO [GroupCoordinator 0]: Member consumer-3-a693a698-fe7a-4786-8899-bd07c2be3ed0 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:08:24,121] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 63 (__consumer_offsets-13) (reason: removing member consumer-3-a693a698-fe7a-4786-8899-bd07c2be3ed0 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:08:25,451] INFO [GroupCoordinator 0]: Stabilized group group_id generation 64 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:08:25,453] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 64 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:08:38,728] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 64 (__consumer_offsets-13) (reason: Adding new member consumer-4-687fd11c-2647-4edf-835d-3a8ce3901a26) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:08:40,460] INFO [GroupCoordinator 0]: Stabilized group group_id generation 65 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:08:40,911] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 65 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:09:30,986] INFO [GroupCoordinator 0]: Member consumer-4-687fd11c-2647-4edf-835d-3a8ce3901a26 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:09:30,987] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 65 (__consumer_offsets-13) (reason: removing member consumer-4-687fd11c-2647-4edf-835d-3a8ce3901a26 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:09:31,925] INFO [GroupCoordinator 0]: Stabilized group group_id generation 66 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:09:31,930] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 66 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:09:42,344] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 66 (__consumer_offsets-13) (reason: Adding new member consumer-5-9336b810-bee1-4fbb-a850-982cf5cd8a1b) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:09:43,940] INFO [GroupCoordinator 0]: Stabilized group group_id generation 67 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:09:44,174] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 67 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:11:22,679] INFO [GroupCoordinator 0]: Member consumer-5-9336b810-bee1-4fbb-a850-982cf5cd8a1b in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:11:22,682] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 67 (__consumer_offsets-13) (reason: removing member consumer-5-9336b810-bee1-4fbb-a850-982cf5cd8a1b on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:11:23,298] INFO [GroupCoordinator 0]: Stabilized group group_id generation 68 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:11:23,300] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 68 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:11:34,262] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 68 (__consumer_offsets-13) (reason: Adding new member consumer-6-e810f6c5-f418-4d22-a6c3-8ef2099e280b) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:11:35,307] INFO [GroupCoordinator 0]: Stabilized group group_id generation 69 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:11:35,600] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 69 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:13:08,558] INFO [GroupCoordinator 0]: Member consumer-6-e810f6c5-f418-4d22-a6c3-8ef2099e280b in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:13:08,558] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 69 (__consumer_offsets-13) (reason: removing member consumer-6-e810f6c5-f418-4d22-a6c3-8ef2099e280b on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:13:08,737] INFO [GroupCoordinator 0]: Stabilized group group_id generation 70 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:13:08,739] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 70 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:13:20,504] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 70 (__consumer_offsets-13) (reason: Adding new member consumer-7-e245e760-c6d0-4531-a6ff-014298d597f1) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:13:20,744] INFO [GroupCoordinator 0]: Stabilized group group_id generation 71 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:13:20,860] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 71 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:13:36,726] INFO [GroupCoordinator 0]: Member consumer-7-e245e760-c6d0-4531-a6ff-014298d597f1 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:13:36,727] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 71 (__consumer_offsets-13) (reason: removing member consumer-7-e245e760-c6d0-4531-a6ff-014298d597f1 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:13:38,868] INFO [GroupCoordinator 0]: Stabilized group group_id generation 72 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:13:38,870] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 72 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:13:47,618] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 72 (__consumer_offsets-13) (reason: Adding new member consumer-8-0b04db38-19d4-403b-85bb-ed5cc649e4ab) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:13:47,874] INFO [GroupCoordinator 0]: Stabilized group group_id generation 73 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:13:47,963] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 73 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:16:22,958] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 15:26:22,959] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 15:36:22,958] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 15:46:22,957] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 15:47:49,785] INFO [GroupCoordinator 0]: Member consumer-8-0b04db38-19d4-403b-85bb-ed5cc649e4ab in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:47:49,786] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 73 (__consumer_offsets-13) (reason: removing member consumer-8-0b04db38-19d4-403b-85bb-ed5cc649e4ab on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:47:51,472] INFO [GroupCoordinator 0]: Stabilized group group_id generation 74 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:47:51,474] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 74 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:48:02,991] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 74 (__consumer_offsets-13) (reason: Adding new member consumer-9-5f3ba8cd-af36-4e02-952c-a1ae8c9e893b) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:48:03,483] INFO [GroupCoordinator 0]: Stabilized group group_id generation 75 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:48:03,964] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 75 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:55:32,500] INFO [GroupCoordinator 0]: Member consumer-9-5f3ba8cd-af36-4e02-952c-a1ae8c9e893b in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:55:32,501] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 75 (__consumer_offsets-13) (reason: removing member consumer-9-5f3ba8cd-af36-4e02-952c-a1ae8c9e893b on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:55:34,136] INFO [GroupCoordinator 0]: Stabilized group group_id generation 76 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:55:34,138] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 76 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:55:44,024] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 76 (__consumer_offsets-13) (reason: Adding new member consumer-10-98c5e62e-1373-425a-82aa-845997fcb2ab) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:55:46,145] INFO [GroupCoordinator 0]: Stabilized group group_id generation 77 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:55:46,582] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 77 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:56:08,590] INFO [GroupCoordinator 0]: Member consumer-10-98c5e62e-1373-425a-82aa-845997fcb2ab in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:56:08,590] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 77 (__consumer_offsets-13) (reason: removing member consumer-10-98c5e62e-1373-425a-82aa-845997fcb2ab on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:56:10,591] INFO [GroupCoordinator 0]: Stabilized group group_id generation 78 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:56:10,593] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 78 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:56:22,959] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 15:59:03,197] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 78 (__consumer_offsets-13) (reason: Adding new member consumer-1-7baacb39-3a21-4a73-ac2a-04a77d08e9a3) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:59:04,626] INFO [GroupCoordinator 0]: Stabilized group group_id generation 79 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 15:59:04,818] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 79 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:06:22,957] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 16:09:18,987] INFO [GroupCoordinator 0]: Member consumer-1-7baacb39-3a21-4a73-ac2a-04a77d08e9a3 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:09:18,988] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 79 (__consumer_offsets-13) (reason: removing member consumer-1-7baacb39-3a21-4a73-ac2a-04a77d08e9a3 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:09:19,936] INFO [GroupCoordinator 0]: Stabilized group group_id generation 80 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:09:19,938] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 80 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:09:34,331] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 80 (__consumer_offsets-13) (reason: Adding new member consumer-2-559655c0-f514-4c5e-9068-fdaf654ae567) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:09:34,945] INFO [GroupCoordinator 0]: Stabilized group group_id generation 81 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:09:35,113] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 81 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:16:22,957] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 16:26:22,968] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 16:36:10,098] INFO [GroupCoordinator 0]: Member consumer-2-559655c0-f514-4c5e-9068-fdaf654ae567 in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:36:10,099] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 81 (__consumer_offsets-13) (reason: removing member consumer-2-559655c0-f514-4c5e-9068-fdaf654ae567 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:36:12,919] INFO [GroupCoordinator 0]: Stabilized group group_id generation 82 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:36:12,921] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 82 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:36:22,962] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 16:36:35,792] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 82 (__consumer_offsets-13) (reason: Adding new member consumer-1-81c66f84-bc4b-4756-843e-fd0045b08978) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:36:36,967] INFO [GroupCoordinator 0]: Stabilized group group_id generation 83 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:36:37,021] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 83 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:40:41,106] INFO [GroupCoordinator 0]: Member consumer-1-81c66f84-bc4b-4756-843e-fd0045b08978 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:40:41,107] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 83 (__consumer_offsets-13) (reason: removing member consumer-1-81c66f84-bc4b-4756-843e-fd0045b08978 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:40:43,097] INFO [GroupCoordinator 0]: Stabilized group group_id generation 84 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:40:43,099] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 84 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:40:56,373] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 84 (__consumer_offsets-13) (reason: Adding new member consumer-2-86cdae71-85ed-4d11-9adf-60d68b2f5c23) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:40:58,119] INFO [GroupCoordinator 0]: Stabilized group group_id generation 85 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:40:58,222] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 85 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:41:47,470] INFO [GroupCoordinator 0]: Member consumer-2-86cdae71-85ed-4d11-9adf-60d68b2f5c23 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:41:47,471] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 85 (__consumer_offsets-13) (reason: removing member consumer-2-86cdae71-85ed-4d11-9adf-60d68b2f5c23 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:41:49,271] INFO [GroupCoordinator 0]: Stabilized group group_id generation 86 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:41:49,273] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 86 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:42:04,567] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 86 (__consumer_offsets-13) (reason: Adding new member consumer-3-50b379ab-9cd4-4929-b751-128cbb30dd6f) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:42:07,292] INFO [GroupCoordinator 0]: Stabilized group group_id generation 87 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:42:07,342] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 87 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:45:04,260] INFO [GroupCoordinator 0]: Member consumer-3-50b379ab-9cd4-4929-b751-128cbb30dd6f in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:45:04,262] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 87 (__consumer_offsets-13) (reason: removing member consumer-3-50b379ab-9cd4-4929-b751-128cbb30dd6f on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:46:22,958] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 16:48:03,307] INFO [GroupCoordinator 0]: Member consumer-1-14fb1947-efa2-443f-a418-37443a544f7a in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:48:03,309] INFO [GroupCoordinator 0]: Group group_id with generation 88 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 16:56:22,959] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 17:06:22,957] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 17:09:19,655] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 88 (__consumer_offsets-13) (reason: Adding new member consumer-1-ee26ffc3-3294-4eff-a3dc-d03b4c61fdd6) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:09:19,659] INFO [GroupCoordinator 0]: Stabilized group group_id generation 89 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:09:19,671] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 89 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:13:05,722] INFO [GroupCoordinator 0]: Member consumer-1-ee26ffc3-3294-4eff-a3dc-d03b4c61fdd6 in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:13:05,723] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 89 (__consumer_offsets-13) (reason: removing member consumer-1-ee26ffc3-3294-4eff-a3dc-d03b4c61fdd6 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:13:05,726] INFO [GroupCoordinator 0]: Group group_id with generation 90 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:13:43,975] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 90 (__consumer_offsets-13) (reason: Adding new member consumer-1-91add81a-3606-4bdd-a6c5-0cfd1971c9ed) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:13:43,978] INFO [GroupCoordinator 0]: Stabilized group group_id generation 91 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:13:43,988] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 91 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:15:39,014] INFO [GroupCoordinator 0]: Member consumer-1-91add81a-3606-4bdd-a6c5-0cfd1971c9ed in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:15:39,015] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 91 (__consumer_offsets-13) (reason: removing member consumer-1-91add81a-3606-4bdd-a6c5-0cfd1971c9ed on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:15:39,018] INFO [GroupCoordinator 0]: Group group_id with generation 92 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:16:22,957] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 17:17:56,191] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 92 (__consumer_offsets-13) (reason: Adding new member consumer-1-844387ec-37dd-4ab0-b9d4-f9b0844b062f) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:17:56,368] INFO [GroupCoordinator 0]: Stabilized group group_id generation 93 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:17:56,480] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 93 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:18:12,564] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 93 (__consumer_offsets-13) (reason: Adding new member consumer-1-f016a0e9-2d41-4c05-a5ce-fb2aaf9993fb) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:19:11,916] INFO [GroupCoordinator 0]: Stabilized group group_id generation 94 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:19:11,922] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 94 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:19:59,719] INFO [GroupCoordinator 0]: Member consumer-1-f016a0e9-2d41-4c05-a5ce-fb2aaf9993fb in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:19:59,720] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 94 (__consumer_offsets-13) (reason: removing member consumer-1-f016a0e9-2d41-4c05-a5ce-fb2aaf9993fb on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:19:59,996] INFO [GroupCoordinator 0]: Stabilized group group_id generation 95 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:19:59,999] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 95 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:20:49,896] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 95 (__consumer_offsets-13) (reason: Adding new member consumer-2-f0247d9d-9c3d-4efd-8b8e-b7a01aada34f) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:20:51,013] INFO [GroupCoordinator 0]: Stabilized group group_id generation 96 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:20:51,338] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 96 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:21:36,689] INFO [GroupCoordinator 0]: Member consumer-2-f0247d9d-9c3d-4efd-8b8e-b7a01aada34f in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:21:36,690] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 96 (__consumer_offsets-13) (reason: removing member consumer-2-f0247d9d-9c3d-4efd-8b8e-b7a01aada34f on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:21:39,349] INFO [GroupCoordinator 0]: Stabilized group group_id generation 97 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:21:39,351] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 97 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:21:50,509] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 97 (__consumer_offsets-13) (reason: Adding new member consumer-3-367c9336-bb04-4558-a22a-8028a065a0a3) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:21:51,357] INFO [GroupCoordinator 0]: Stabilized group group_id generation 98 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:21:51,614] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 98 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:25:08,953] INFO [GroupCoordinator 0]: Member consumer-3-367c9336-bb04-4558-a22a-8028a065a0a3 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:25:08,955] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 98 (__consumer_offsets-13) (reason: removing member consumer-3-367c9336-bb04-4558-a22a-8028a065a0a3 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:25:09,845] INFO [GroupCoordinator 0]: Stabilized group group_id generation 99 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:25:09,847] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 99 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:25:21,527] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 99 (__consumer_offsets-13) (reason: Adding new member consumer-4-9a979ac8-b26a-4881-afc8-31383bf3a248) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:25:21,853] INFO [GroupCoordinator 0]: Stabilized group group_id generation 100 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:25:22,080] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 100 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:26:22,957] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 17:32:43,740] INFO [GroupCoordinator 0]: Member consumer-4-9a979ac8-b26a-4881-afc8-31383bf3a248 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:32:43,742] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 100 (__consumer_offsets-13) (reason: removing member consumer-4-9a979ac8-b26a-4881-afc8-31383bf3a248 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:32:46,232] INFO [GroupCoordinator 0]: Stabilized group group_id generation 101 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:32:46,234] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 101 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:33:05,443] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 101 (__consumer_offsets-13) (reason: Adding new member consumer-5-269f26b1-b5e8-4635-a229-931044e12f49) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:33:07,243] INFO [GroupCoordinator 0]: Stabilized group group_id generation 102 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:33:07,409] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 102 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:36:22,957] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 17:38:08,467] INFO [GroupCoordinator 0]: Member consumer-5-269f26b1-b5e8-4635-a229-931044e12f49 in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:38:08,467] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 102 (__consumer_offsets-13) (reason: removing member consumer-5-269f26b1-b5e8-4635-a229-931044e12f49 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:38:10,560] INFO [GroupCoordinator 0]: Stabilized group group_id generation 103 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:38:10,561] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 103 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:39:01,289] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 103 (__consumer_offsets-13) (reason: Adding new member consumer-1-8ee5e672-753a-4f3a-b46e-1c072550d395) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:39:01,577] INFO [GroupCoordinator 0]: Stabilized group group_id generation 104 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:39:01,794] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 104 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:44:19,127] INFO [GroupCoordinator 0]: Member consumer-1-8ee5e672-753a-4f3a-b46e-1c072550d395 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:44:19,128] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 104 (__consumer_offsets-13) (reason: removing member consumer-1-8ee5e672-753a-4f3a-b46e-1c072550d395 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:44:20,184] INFO [GroupCoordinator 0]: Stabilized group group_id generation 105 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:44:20,186] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 105 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:44:50,934] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 105 (__consumer_offsets-13) (reason: Adding new member consumer-2-bb9fb237-cc13-46e1-955e-142e4e38792b) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:44:53,196] INFO [GroupCoordinator 0]: Stabilized group group_id generation 106 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:44:53,291] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 106 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:46:22,957] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 17:55:27,041] INFO [GroupCoordinator 0]: Member consumer-2-bb9fb237-cc13-46e1-955e-142e4e38792b in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:55:27,042] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 106 (__consumer_offsets-13) (reason: removing member consumer-2-bb9fb237-cc13-46e1-955e-142e4e38792b on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:55:29,563] INFO [GroupCoordinator 0]: Stabilized group group_id generation 107 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:55:29,564] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 107 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:55:41,541] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 107 (__consumer_offsets-13) (reason: Adding new member consumer-3-759e606c-09c8-4e3e-b69c-11fe2cb088e1) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:55:41,576] INFO [GroupCoordinator 0]: Stabilized group group_id generation 108 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:55:41,903] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 108 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:56:22,957] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-18 17:56:31,250] INFO [GroupCoordinator 0]: Member consumer-3-759e606c-09c8-4e3e-b69c-11fe2cb088e1 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:56:31,251] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 108 (__consumer_offsets-13) (reason: removing member consumer-3-759e606c-09c8-4e3e-b69c-11fe2cb088e1 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:56:33,022] INFO [GroupCoordinator 0]: Stabilized group group_id generation 109 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:56:33,024] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 109 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:56:45,116] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 109 (__consumer_offsets-13) (reason: Adding new member consumer-4-7fe2d723-df88-4c10-9423-4253600f94e3) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:56:48,032] INFO [GroupCoordinator 0]: Stabilized group group_id generation 110 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:56:48,222] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 110 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:59:00,459] INFO [GroupCoordinator 0]: Member consumer-4-7fe2d723-df88-4c10-9423-4253600f94e3 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:59:00,461] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 110 (__consumer_offsets-13) (reason: removing member consumer-4-7fe2d723-df88-4c10-9423-4253600f94e3 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:59:03,252] INFO [GroupCoordinator 0]: Stabilized group group_id generation 111 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:59:03,254] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 111 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:59:34,865] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 111 (__consumer_offsets-13) (reason: Adding new member consumer-5-41ea1a82-f69d-43e7-b1dc-9cb46ad4a00c) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:59:36,266] INFO [GroupCoordinator 0]: Stabilized group group_id generation 112 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 17:59:36,365] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 112 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 18:05:09,188] INFO [GroupCoordinator 0]: Member consumer-5-41ea1a82-f69d-43e7-b1dc-9cb46ad4a00c in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 18:05:09,197] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 112 (__consumer_offsets-13) (reason: removing member consumer-5-41ea1a82-f69d-43e7-b1dc-9cb46ad4a00c on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 18:05:09,622] INFO [GroupCoordinator 0]: Stabilized group group_id generation 113 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 18:05:09,624] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 113 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 18:05:38,011] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 113 (__consumer_offsets-13) (reason: Adding new member consumer-6-f9e6492d-838f-474e-8034-a213aa930d55) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 18:05:39,633] INFO [GroupCoordinator 0]: Stabilized group group_id generation 114 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 18:05:39,879] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 114 (kafka.coordinator.group.GroupCoordinator)
[2020-02-18 18:06:22,958] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:06:04,977] INFO [GroupCoordinator 0]: Member consumer-1-844387ec-37dd-4ab0-b9d4-f9b0844b062f in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 10:06:04,997] WARN Client session timed out, have not heard from server in 57342447ms for sessionid 0x1000167d2c90002 (org.apache.zookeeper.ClientCnxn)
[2020-02-19 10:06:05,754] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 114 (__consumer_offsets-13) (reason: removing member consumer-1-844387ec-37dd-4ab0-b9d4-f9b0844b062f on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 10:06:05,791] INFO Client session timed out, have not heard from server in 57342447ms for sessionid 0x1000167d2c90002, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2020-02-19 10:06:06,075] INFO [GroupCoordinator 0]: Stabilized group group_id generation 115 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 10:06:05,101] INFO Expiring session 0x1000167d2c90002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-19 10:06:06,115] WARN Unable to read additional data from client sessionid 0x1000167d2c90002, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-19 10:06:06,305] INFO Processed session termination for sessionid: 0x1000167d2c90002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-19 10:06:06,700] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 115 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 10:06:06,718] INFO Closed socket connection for client /127.0.0.1:2813 which had sessionid 0x1000167d2c90002 (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-19 10:06:07,698] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-02-19 10:06:07,881] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:3370 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-19 10:06:07,877] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-02-19 10:06:08,080] INFO Client attempting to renew session 0x1000167d2c90002 at /0:0:0:0:0:0:0:1:3370 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-19 10:06:08,253] INFO Invalid session 0x1000167d2c90002 for client /0:0:0:0:0:0:0:1:3370, probably expired (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-19 10:06:08,265] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:3370 which had sessionid 0x1000167d2c90002 (org.apache.zookeeper.server.NIOServerCnxn)
[2020-02-19 10:06:08,256] WARN Unable to reconnect to ZooKeeper service, session 0x1000167d2c90002 has expired (org.apache.zookeeper.ClientCnxn)
[2020-02-19 10:06:08,305] INFO Unable to reconnect to ZooKeeper service, session 0x1000167d2c90002 has expired, closing socket connection (org.apache.zookeeper.ClientCnxn)
[2020-02-19 10:06:08,266] INFO [ZooKeeperClient] Session expired. (kafka.zookeeper.ZooKeeperClient)
[2020-02-19 10:06:08,266] INFO EventThread shut down for session: 0x1000167d2c90002 (org.apache.zookeeper.ClientCnxn)
[2020-02-19 10:06:08,759] INFO [ZooKeeperClient] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-02-19 10:06:09,039] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@769f71a9 (org.apache.zookeeper.ZooKeeper)
[2020-02-19 10:06:09,111] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-02-19 10:06:09,277] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-02-19 10:06:09,343] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:3381 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-02-19 10:06:09,343] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2020-02-19 10:06:09,431] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:3381 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-19 10:06:09,510] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000167d2c90004, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-02-19 10:06:09,510] INFO Established session 0x1000167d2c90004 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:3381 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-02-19 10:06:09,930] INFO Stat of the created znode at /brokers/ids/0 is: 162,162,1582099569643,1582099569643,1,0,0,72059139467575300,222,0,162
 (kafka.zk.KafkaZkClient)
[2020-02-19 10:06:10,489] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(aviramco02.corp.amdocs.com,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 162 (kafka.zk.KafkaZkClient)
[2020-02-19 10:06:14,044] INFO Got user-level KeeperException when processing sessionid:0x1000167d2c90004 type:multi cxid:0x4d zxid:0xa4 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2020-02-19 10:12:03,387] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,388] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,390] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,391] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,392] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,392] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,394] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,395] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,396] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,397] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,397] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,400] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,401] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,401] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,401] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,402] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,403] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,404] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,404] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,405] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,405] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,406] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,406] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,407] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,407] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,408] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,408] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,410] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,411] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,412] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,412] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,413] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,413] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,414] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,414] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,415] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,415] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,416] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,416] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,417] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,417] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,418] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,418] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,419] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,421] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,422] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,423] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,423] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,424] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,424] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,425] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,425] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,426] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,427] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,428] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,428] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,429] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,429] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,430] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,430] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,433] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,433] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,434] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,435] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,436] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,437] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,437] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,438] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,438] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,439] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,440] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,441] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,441] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,442] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,442] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,443] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,443] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,444] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,444] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,444] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,445] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,445] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,446] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,446] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,447] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,448] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,448] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,449] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,451] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,451] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,452] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,452] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,453] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,454] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,454] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:12:03,455] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:16:22,950] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:26:22,940] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:36:22,485] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:46:22,495] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 10:56:22,496] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 11:06:22,476] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 11:16:22,476] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 11:26:22,474] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 11:36:22,475] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 11:46:22,474] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 11:56:22,484] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 12:06:22,489] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 12:16:22,478] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 12:26:22,479] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 12:36:22,480] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 12:46:22,480] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 12:56:22,481] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 13:06:22,479] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 13:16:22,479] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 13:26:22,485] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 13:35:47,594] INFO [GroupCoordinator 0]: Member consumer-6-f9e6492d-838f-474e-8034-a213aa930d55 in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:35:47,603] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 115 (__consumer_offsets-13) (reason: removing member consumer-6-f9e6492d-838f-474e-8034-a213aa930d55 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:35:50,709] INFO [GroupCoordinator 0]: Member consumer-1-c269dbf3-1da3-46ae-8c6c-9c70f7400927 in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:35:50,710] INFO [GroupCoordinator 0]: Group group_id with generation 116 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:36:22,500] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 13:37:10,787] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 116 (__consumer_offsets-13) (reason: Adding new member consumer-1-f1570b00-6c39-43fe-b313-5afdbdba7d9d) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:37:10,832] INFO [GroupCoordinator 0]: Stabilized group group_id generation 117 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:37:10,846] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 117 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:37:15,740] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 117 (__consumer_offsets-13) (reason: Adding new member consumer-1-c551ef23-285f-43bf-8209-45a1c7467849) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:37:16,862] INFO [GroupCoordinator 0]: Stabilized group group_id generation 118 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:37:17,062] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 118 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:39:00,137] INFO [GroupCoordinator 0]: Member consumer-1-c551ef23-285f-43bf-8209-45a1c7467849 in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:39:00,138] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 118 (__consumer_offsets-13) (reason: removing member consumer-1-c551ef23-285f-43bf-8209-45a1c7467849 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:39:02,557] INFO [GroupCoordinator 0]: Stabilized group group_id generation 119 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:39:02,560] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 119 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:39:39,713] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 119 (__consumer_offsets-13) (reason: Adding new member consumer-1-e8a650d5-8d26-496f-a958-14ce764c842b) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:39:41,576] INFO [GroupCoordinator 0]: Stabilized group group_id generation 120 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:39:41,912] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 120 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:46:22,468] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 13:54:24,292] INFO [GroupCoordinator 0]: Member consumer-1-aa6a9281-183a-4dfb-b451-434920cd1df5 in group console-consumer-87811 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:54:24,292] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-87811 in state PreparingRebalance with old generation 1 (__consumer_offsets-16) (reason: removing member consumer-1-aa6a9281-183a-4dfb-b451-434920cd1df5 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:54:24,294] INFO [GroupCoordinator 0]: Group console-consumer-87811 with generation 2 is now empty (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 13:56:22,496] INFO [GroupMetadataManager brokerId=0] Group console-consumer-87811 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 13:56:22,507] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 41 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 14:06:22,465] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 14:06:29,835] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-87811 in state PreparingRebalance with old generation 0 (__consumer_offsets-16) (reason: Adding new member consumer-1-4ea50ca4-ab5e-4e5a-aefb-7cc4b023c5b0) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:06:29,837] INFO [GroupCoordinator 0]: Stabilized group console-consumer-87811 generation 1 (__consumer_offsets-16) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:06:29,849] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-87811 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:16:22,465] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 14:26:22,464] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 14:35:24,442] INFO [GroupCoordinator 0]: Member consumer-1-e8a650d5-8d26-496f-a958-14ce764c842b in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:35:24,443] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 120 (__consumer_offsets-13) (reason: removing member consumer-1-e8a650d5-8d26-496f-a958-14ce764c842b on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:35:25,973] INFO [GroupCoordinator 0]: Stabilized group group_id generation 121 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:35:25,976] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 121 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:35:42,008] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 121 (__consumer_offsets-13) (reason: Adding new member consumer-2-85aa5070-0a32-4914-967e-daf132ac872c) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:35:43,986] INFO [GroupCoordinator 0]: Stabilized group group_id generation 122 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:35:44,163] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 122 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:36:22,465] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 14:36:41,710] INFO [GroupCoordinator 0]: Member consumer-2-85aa5070-0a32-4914-967e-daf132ac872c in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:36:41,714] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 122 (__consumer_offsets-13) (reason: removing member consumer-2-85aa5070-0a32-4914-967e-daf132ac872c on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:36:44,178] INFO [GroupCoordinator 0]: Stabilized group group_id generation 123 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:36:44,180] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 123 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:36:57,842] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 123 (__consumer_offsets-13) (reason: Adding new member consumer-3-23f377b9-704d-4c4b-81a8-2fceb99212e2) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:36:59,188] INFO [GroupCoordinator 0]: Stabilized group group_id generation 124 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:36:59,493] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 124 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:36:59,897] INFO [GroupCoordinator 0]: Member consumer-3-23f377b9-704d-4c4b-81a8-2fceb99212e2 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:36:59,899] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 124 (__consumer_offsets-13) (reason: removing member consumer-3-23f377b9-704d-4c4b-81a8-2fceb99212e2 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:37:02,498] INFO [GroupCoordinator 0]: Stabilized group group_id generation 125 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:37:02,500] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 125 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:37:34,797] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 125 (__consumer_offsets-13) (reason: Adding new member consumer-4-905b2d6d-2158-4732-a006-5ea8da294616) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:37:35,509] INFO [GroupCoordinator 0]: Stabilized group group_id generation 126 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:37:35,654] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 126 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:44:57,728] INFO [GroupCoordinator 0]: Member consumer-4-905b2d6d-2158-4732-a006-5ea8da294616 in group group_id has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:44:57,729] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 126 (__consumer_offsets-13) (reason: removing member consumer-4-905b2d6d-2158-4732-a006-5ea8da294616 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:44:59,728] INFO [GroupCoordinator 0]: Stabilized group group_id generation 127 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:44:59,729] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 127 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:46:22,464] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 14:47:25,700] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 127 (__consumer_offsets-13) (reason: Adding new member consumer-1-2d57fff5-5b11-48e3-ae21-ec5ec8db751b) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:47:26,763] INFO [GroupCoordinator 0]: Stabilized group group_id generation 128 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:47:26,764] INFO [GroupCoordinator 0]: Member consumer-1-2d57fff5-5b11-48e3-ae21-ec5ec8db751b in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:47:26,778] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 128 (__consumer_offsets-13) (reason: removing member consumer-1-2d57fff5-5b11-48e3-ae21-ec5ec8db751b on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:47:27,141] INFO [GroupCoordinator 0]: Stabilized group group_id generation 129 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:47:27,142] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 129 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:52:06,439] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 129 (__consumer_offsets-13) (reason: Adding new member consumer-1-f353a8eb-321e-4d92-9dc0-0eb845f2f644) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:52:09,203] INFO [GroupCoordinator 0]: Stabilized group group_id generation 130 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:52:09,209] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 130 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:52:57,729] INFO [GroupCoordinator 0]: Member consumer-1-f353a8eb-321e-4d92-9dc0-0eb845f2f644 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:52:57,732] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 130 (__consumer_offsets-13) (reason: removing member consumer-1-f353a8eb-321e-4d92-9dc0-0eb845f2f644 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:53:00,226] INFO [GroupCoordinator 0]: Stabilized group group_id generation 131 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:53:00,228] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 131 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:53:35,057] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 131 (__consumer_offsets-13) (reason: Adding new member consumer-2-96d894c3-e8fa-4efb-a246-e70a4edeb5b7) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:53:36,237] INFO [GroupCoordinator 0]: Stabilized group group_id generation 132 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:53:36,545] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 132 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:55:10,225] INFO [GroupCoordinator 0]: Member consumer-2-96d894c3-e8fa-4efb-a246-e70a4edeb5b7 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:55:10,228] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 132 (__consumer_offsets-13) (reason: removing member consumer-2-96d894c3-e8fa-4efb-a246-e70a4edeb5b7 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:55:12,559] INFO [GroupCoordinator 0]: Stabilized group group_id generation 133 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:55:12,561] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 133 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:55:31,909] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 133 (__consumer_offsets-13) (reason: Adding new member consumer-3-a08e8ecd-c745-4830-9d92-c750d9b403fe) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:55:33,567] INFO [GroupCoordinator 0]: Stabilized group group_id generation 134 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:55:33,969] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 134 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:56:22,463] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 14:57:57,875] INFO [GroupCoordinator 0]: Member consumer-3-a08e8ecd-c745-4830-9d92-c750d9b403fe in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:57:57,876] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 134 (__consumer_offsets-13) (reason: removing member consumer-3-a08e8ecd-c745-4830-9d92-c750d9b403fe on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:57:57,998] INFO [GroupCoordinator 0]: Stabilized group group_id generation 135 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:57:58,000] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 135 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:58:11,298] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 135 (__consumer_offsets-13) (reason: Adding new member consumer-4-7501cf91-397e-481a-bb55-e3a71e0e3f39) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:58:13,010] INFO [GroupCoordinator 0]: Stabilized group group_id generation 136 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 14:58:13,057] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 136 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:04:11,099] INFO [GroupCoordinator 0]: Member consumer-4-7501cf91-397e-481a-bb55-e3a71e0e3f39 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:04:11,118] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 136 (__consumer_offsets-13) (reason: removing member consumer-4-7501cf91-397e-481a-bb55-e3a71e0e3f39 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:04:13,338] INFO [GroupCoordinator 0]: Stabilized group group_id generation 137 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:04:13,340] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 137 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:04:32,678] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 137 (__consumer_offsets-13) (reason: Adding new member consumer-5-4e3a2e73-bca8-43cd-951e-275f7764f206) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:04:34,345] INFO [GroupCoordinator 0]: Stabilized group group_id generation 138 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:04:34,743] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 138 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:06:22,464] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 15:08:48,944] INFO [GroupCoordinator 0]: Member consumer-5-4e3a2e73-bca8-43cd-951e-275f7764f206 in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:08:48,945] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 138 (__consumer_offsets-13) (reason: removing member consumer-5-4e3a2e73-bca8-43cd-951e-275f7764f206 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:08:49,892] INFO [GroupCoordinator 0]: Stabilized group group_id generation 139 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:08:49,894] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 139 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:09:07,061] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 139 (__consumer_offsets-13) (reason: Adding new member consumer-6-7a40e747-1508-4f62-ab4b-ff1a19e26baf) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:09:07,902] INFO [GroupCoordinator 0]: Stabilized group group_id generation 140 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:09:08,277] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 140 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:11:59,577] INFO [GroupCoordinator 0]: Member consumer-6-7a40e747-1508-4f62-ab4b-ff1a19e26baf in group group_id has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:11:59,578] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 140 (__consumer_offsets-13) (reason: removing member consumer-6-7a40e747-1508-4f62-ab4b-ff1a19e26baf on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:12:02,433] INFO [GroupCoordinator 0]: Stabilized group group_id generation 141 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:12:02,435] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 141 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:12:13,414] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id in state PreparingRebalance with old generation 141 (__consumer_offsets-13) (reason: Adding new member consumer-7-bdebfa1c-8f8f-4e77-89a3-c7c6ac92c220) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:12:14,441] INFO [GroupCoordinator 0]: Stabilized group group_id generation 142 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:12:14,899] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id for generation 142 (kafka.coordinator.group.GroupCoordinator)
[2020-02-19 15:16:22,463] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 15:26:22,464] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 15:36:22,464] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 15:46:22,462] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 15:56:22,462] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 16:06:22,462] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 16:16:22,463] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 16:26:22,462] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 16:36:22,463] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 16:46:22,462] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 16:56:22,463] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 17:06:22,464] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 17:16:22,463] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 17:26:22,462] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 17:36:22,463] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-02-19 17:46:22,463] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
